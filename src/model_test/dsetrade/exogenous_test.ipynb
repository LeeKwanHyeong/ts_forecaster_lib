{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T02:22:04.477427Z",
     "start_time": "2026-01-19T02:22:04.463060Z"
    }
   },
   "source": [
    "from modeling_module.training.forecaster import make_calendar_exo\n",
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "\n",
    "dir = \"C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/\"         # default project directory\\\n",
    "save_dir = os.path.join(dir, 'fit')\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "save_root = os.path.join(save_dir, 'Xpatchtst', '20260119')\n",
    "\n",
    "plan_week = 201103\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lookback = 52\n",
    "horizon = 27\n",
    "batch_size = 256\n",
    "freq = 'weekly'\n",
    "split_mode = 'multi'\n",
    "shuffle = True\n",
    "id_col = 'unique_id'\n",
    "date_col = 'date'\n",
    "y_col = 'y'\n",
    "\n",
    "# add past exogenous continuous variable columns\n",
    "past_exo_cont_cols = (\n",
    "    # \"exo_p_y_lag_1w\",\n",
    "    \"exo_p_y_lag_2w\",\n",
    "    # \"exo_p_y_lag_52w\",\n",
    "    \"exo_p_y_rollmean_4w\",\"exo_p_y_rollmean_12w\",\"exo_p_y_rollstd_4w\",\n",
    "    # \"exo_p_weeks_since_holiday\",\n",
    "    # \"exo_p_temperature\",\n",
    "    # \"exo_p_fuel_price\",\n",
    "    # \"exo_p_cpi\",\n",
    "    # \"exo_p_unemployment\",\n",
    "    # \"exo_p_markdown_sum\",\n",
    "    # \"exo_p_markdown1\",\n",
    "    # \"exo_p_markdown2\",\n",
    "    # \"exo_p_markdown3\",\n",
    "    # \"exo_p_markdown4\",\n",
    "    # \"exo_p_markdown5\",\n",
    "    # \"exo_markdown1_isnull\",\n",
    "    # \"exo_markdown2_isnull\",\n",
    "    # \"exo_markdown3_isnull\",\n",
    "    # \"exo_markdown4_isnull\",\n",
    "    # \"exo_markdown5_isnull\",\n",
    ")\n",
    "\n",
    "# add past exogenous categorical variable columns\n",
    "past_exo_cat_cols = (\n",
    "    # \"exo_c_woy_bucket\",\n",
    ")\n",
    "\n",
    "def my_exo_cb(start_idx: int, Hm: int, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # exo_dim = 2 (sin, cos)\n",
    "    return make_calendar_exo(start_idx, Hm, period=52, device=device)\n",
    "\n",
    "future_exo_cb = my_exo_cb\n",
    "\n",
    "# real dataframe\n",
    "df = pl.read_parquet(dir + 'train_data/walmart_best_feature_train.parquet')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T02:22:05.067982Z",
     "start_time": "2026-01-19T02:22:05.060679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling_module.training.forecater import DMSForecaster\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from datetime import date, timedelta\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# YYYYWW(ISO week) 유틸\n",
    "# -----------------------------\n",
    "def yyyyww_to_monday(yyyyww: int) -> date:\n",
    "    y = int(yyyyww) // 100\n",
    "    w = int(yyyyww) % 100\n",
    "    return date.fromisocalendar(y, w, 1)\n",
    "\n",
    "def monday_to_yyyyww(d: date) -> int:\n",
    "    iso_y, iso_w, _ = d.isocalendar()\n",
    "    return int(iso_y) * 100 + int(iso_w)\n",
    "\n",
    "def add_week(yyyyww: int, add: int) -> int:\n",
    "    return monday_to_yyyyww(yyyyww_to_monday(yyyyww) + timedelta(weeks=int(add)))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 결과 테이블 생성 함수\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def make_forecast_result_table(\n",
    "    *,\n",
    "    inference_loader,\n",
    "    base_model: torch.nn.Module,\n",
    "    quantile_model: torch.nn.Module,\n",
    "    plan_week: int,\n",
    "    horizon: int,\n",
    "    device: str = \"cuda\",\n",
    "    max_parts: int = 10_000,          # 필요시 제한\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    inference_loader 배치에서 (x, y, uid, fe, pe_cont, pe_cat)을 받아\n",
    "    - base_model: point forecast\n",
    "    - quantile_model: q50 forecast\n",
    "    를 만든 후,\n",
    "    (oper_part_no, forecast_week) 단위의 long table로 반환\n",
    "    \"\"\"\n",
    "\n",
    "    base_fc = DMSForecaster(base_model, target_channel=0, fill_mode=\"copy_last\")\n",
    "    q_fc    = DMSForecaster(quantile_model, target_channel=0, fill_mode=\"copy_last\")\n",
    "\n",
    "    rows = []\n",
    "    n_parts = 0\n",
    "\n",
    "    for batch in inference_loader:\n",
    "        # exogenous_test의 inspect()와 동일한 배치 구조 가정\n",
    "        x, uid, fe, pe_cont, pe_cat = batch\n",
    "\n",
    "        B = x.size(0)\n",
    "        for i in range(B):\n",
    "            if n_parts >= max_parts:\n",
    "                break\n",
    "\n",
    "            x1 = x[i:i+1]\n",
    "            pid = uid[i]  # oper_part_no로 사용(필요하면 mapping)\n",
    "\n",
    "            fe1 = fe[i:i+1] if fe is not None else None\n",
    "            pec1 = pe_cont[i:i+1] if pe_cont is not None else None\n",
    "            pek1 = pe_cat[i:i+1] if pe_cat is not None else None\n",
    "\n",
    "            # Base(Point) 예측\n",
    "            pred_base = base_fc.predict(\n",
    "                x1,\n",
    "                horizon=int(horizon),\n",
    "                device=device,\n",
    "                mode=\"eval\",\n",
    "                part_ids=[pid] if pid is not None else None,\n",
    "                past_exo_cont=pec1,\n",
    "                past_exo_cat=pek1,\n",
    "                future_exo_batch=fe1,\n",
    "            )\n",
    "            y_base = np.asarray(pred_base[\"point\"]).reshape(-1)  # (H,)\n",
    "\n",
    "            # Quantile(q50) 예측\n",
    "            pred_q = q_fc.predict(\n",
    "                x1,\n",
    "                horizon=int(horizon),\n",
    "                device=device,\n",
    "                mode=\"eval\",\n",
    "                part_ids=[pid] if pid is not None else None,\n",
    "                past_exo_cont=pec1,\n",
    "                past_exo_cat=pek1,\n",
    "                future_exo_batch=fe1,\n",
    "            )\n",
    "            # forecater_v2는 quantile이면 q50을 point로도 넣어주지만, 명시적으로 q50 우선 사용\n",
    "            y_q50 = np.asarray(pred_q.get(\"q50\", pred_q[\"point\"])).reshape(-1)  # (H,)\n",
    "\n",
    "            # 주차 생성: plan_week 포함하여 horizon개\n",
    "            weeks = [add_week(plan_week, h) for h in range(int(horizon))]\n",
    "\n",
    "            # long rows 적재\n",
    "            pid_str = str(pid.item()) if torch.is_tensor(pid) and pid.numel() == 1 else str(pid)\n",
    "            for w, bval, qval in zip(weeks, y_base.tolist(), y_q50.tolist()):\n",
    "                rows.append({\n",
    "                    \"plan_week\": int(plan_week),\n",
    "                    \"oper_part_no\": pid_str,\n",
    "                    \"forecast_week\": int(w),\n",
    "                    \"base_forecast\": float(bval),\n",
    "                    \"quantile_forecast\": float(qval),\n",
    "                })\n",
    "\n",
    "            n_parts += 1\n",
    "\n",
    "        if n_parts >= max_parts:\n",
    "            break\n",
    "\n",
    "    return pl.DataFrame(rows)"
   ],
   "id": "b70a7f8ac8a36ebe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T02:22:06.023313Z",
     "start_time": "2026-01-19T02:22:05.598938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling_module.utils.checkpoint import load_model_dict\n",
    "from modeling_module.models import build_patchTST_quantile, build_patchTST_base\n",
    "from modeling_module.data_loader import MultiPartExoDataModule\n",
    "from modeling_module.training.model_trainers.total_train import run_total_train_weekly\n",
    "\n",
    "def inspect(loader, name):\n",
    "    b = next(iter(loader))\n",
    "    x, uid, fe, pe_cont, pe_cat = b\n",
    "    print(f\"[{name}] x:\", x.shape, x.device, x.dtype)\n",
    "    print(f\"[{name}] fe:\", fe.shape, fe.device, fe.dtype)\n",
    "    print(f\"[{name}] pe:\", pe_cont.shape, pe_cont.device, pe_cont.dtype)\n",
    "    # print(f\"[{name}] future_exo_cb is None?\", loader.collate_fn.future_exo_cb is None)\n",
    "    if fe.shape[-1] > 0:\n",
    "        print(f\"[{name}] fe sample:\", fe[0, :3, :])\n",
    "\n",
    "data_module = MultiPartExoDataModule(\n",
    "    df = df,\n",
    "    id_col = id_col,\n",
    "    date_col = date_col,\n",
    "    y_col = y_col,\n",
    "    lookback = lookback,\n",
    "    horizon = horizon,\n",
    "    batch_size = batch_size,\n",
    "    past_exo_cont_cols = past_exo_cont_cols,\n",
    "    past_exo_cat_cols = past_exo_cat_cols,\n",
    "    future_exo_cb = future_exo_cb,\n",
    "    freq = freq,\n",
    "    shuffle = shuffle,\n",
    "    split_mode = split_mode,\n",
    ")\n",
    "\n",
    "inference_loader = data_module.get_inference_loader_at_plan(plan_dt = plan_week)\n",
    "\n",
    "# for batch in inference_loader:\n",
    "#     print(batch)\n",
    "#     break\n",
    "\n",
    "inspect(inference_loader, 'inference_loader')\n",
    "\n",
    "builders = {\n",
    "    'patchtst_quantile': build_patchTST_quantile,\n",
    "    'patchtst': build_patchTST_base,\n",
    "}\n",
    "\n",
    "model_loader = load_model_dict(save_root, builders, device = device)\n",
    "base_model = model_loader['patchtst']\n",
    "quantile_model = model_loader['patchtst_quantile']\n",
    "\n",
    "result_df = make_forecast_result_table(\n",
    "    inference_loader=inference_loader,\n",
    "    base_model=base_model,\n",
    "    quantile_model=quantile_model,\n",
    "    plan_week=plan_week,\n",
    "    horizon=horizon,\n",
    "    device=device,\n",
    "    max_parts=10_000,\n",
    ")\n",
    "\n"
   ],
   "id": "273d9499547818d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inference_loader] x: torch.Size([45, 52, 1]) cpu torch.float32\n",
      "[inference_loader] fe: torch.Size([45, 27, 2]) cpu torch.float32\n",
      "[inference_loader] pe: torch.Size([45, 52, 4]) cpu torch.float32\n",
      "[inference_loader] fe sample: tensor([[ 0.7474, -0.6643],\n",
      "        [ 0.6617, -0.7498],\n",
      "        [ 0.5679, -0.8231]])\n",
      "[load] patchtst_quantile ← C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/fit\\Xpatchtst\\20260119\\weekly_PatchTSTQuantile_L52_H27.pt\n",
      "[DBG-backbone-init] d_past_cont=4 cont_input_dim=48 target_input_dim=12 total_input_dim=60\n",
      "[load][patchtst_quantile] missing=2 unexpected=0\n",
      "  missing sample: ['revin_layer.mean', 'revin_layer.std']\n",
      "  unexpected sample: []\n",
      "[load] patchtst ← C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/fit\\Xpatchtst\\20260119\\weekly_PatchTSTBase_L52_H27.pt\n",
      "[DBG-backbone-init] d_past_cont=4 cont_input_dim=48 target_input_dim=12 total_input_dim=60\n",
      "[load][patchtst] missing=2 unexpected=0\n",
      "  missing sample: ['revin_layer.mean', 'revin_layer.std']\n",
      "  unexpected sample: []\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T02:22:11.297229Z",
     "start_time": "2026-01-19T02:22:11.292168Z"
    }
   },
   "cell_type": "code",
   "source": "result_df",
   "id": "d231c7de7ba70792",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1_215, 5)\n",
       "┌───────────┬──────────────┬───────────────┬───────────────┬───────────────────┐\n",
       "│ plan_week ┆ oper_part_no ┆ forecast_week ┆ base_forecast ┆ quantile_forecast │\n",
       "│ ---       ┆ ---          ┆ ---           ┆ ---           ┆ ---               │\n",
       "│ i64       ┆ str          ┆ i64           ┆ f64           ┆ f64               │\n",
       "╞═══════════╪══════════════╪═══════════════╪═══════════════╪═══════════════════╡\n",
       "│ 201103    ┆ 1            ┆ 201103        ┆ 890844.25     ┆ 1.3086e6          │\n",
       "│ 201103    ┆ 1            ┆ 201104        ┆ 858298.5      ┆ 1.3666e6          │\n",
       "│ 201103    ┆ 1            ┆ 201105        ┆ 1.2527e6      ┆ 1.4038e6          │\n",
       "│ 201103    ┆ 1            ┆ 201106        ┆ 1.2568e6      ┆ 1.4219e6          │\n",
       "│ 201103    ┆ 1            ┆ 201107        ┆ 1.4789e6      ┆ 1343859.5         │\n",
       "│ …         ┆ …            ┆ …             ┆ …             ┆ …                 │\n",
       "│ 201103    ┆ 9            ┆ 201125        ┆ 501744.6875   ┆ 519144.125        │\n",
       "│ 201103    ┆ 9            ┆ 201126        ┆ 547227.5625   ┆ 500923.84375      │\n",
       "│ 201103    ┆ 9            ┆ 201127        ┆ 520996.375    ┆ 496747.4375       │\n",
       "│ 201103    ┆ 9            ┆ 201128        ┆ 495675.6875   ┆ 500610.875        │\n",
       "│ 201103    ┆ 9            ┆ 201129        ┆ 459380.21875  ┆ 501045.15625      │\n",
       "└───────────┴──────────────┴───────────────┴───────────────┴───────────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_215, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>plan_week</th><th>oper_part_no</th><th>forecast_week</th><th>base_forecast</th><th>quantile_forecast</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>201103</td><td>&quot;1&quot;</td><td>201103</td><td>890844.25</td><td>1.3086e6</td></tr><tr><td>201103</td><td>&quot;1&quot;</td><td>201104</td><td>858298.5</td><td>1.3666e6</td></tr><tr><td>201103</td><td>&quot;1&quot;</td><td>201105</td><td>1.2527e6</td><td>1.4038e6</td></tr><tr><td>201103</td><td>&quot;1&quot;</td><td>201106</td><td>1.2568e6</td><td>1.4219e6</td></tr><tr><td>201103</td><td>&quot;1&quot;</td><td>201107</td><td>1.4789e6</td><td>1343859.5</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>201103</td><td>&quot;9&quot;</td><td>201125</td><td>501744.6875</td><td>519144.125</td></tr><tr><td>201103</td><td>&quot;9&quot;</td><td>201126</td><td>547227.5625</td><td>500923.84375</td></tr><tr><td>201103</td><td>&quot;9&quot;</td><td>201127</td><td>520996.375</td><td>496747.4375</td></tr><tr><td>201103</td><td>&quot;9&quot;</td><td>201128</td><td>495675.6875</td><td>500610.875</td></tr><tr><td>201103</td><td>&quot;9&quot;</td><td>201129</td><td>459380.21875</td><td>501045.15625</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "92d2ae70b754f3ad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T03:57:18.785923Z",
     "start_time": "2026-01-19T03:57:17.561484Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "\n",
    "dir = \"C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/\"        # default project directory\\\n",
    "save_dir = os.path.join(dir, 'fit')\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "save_root = os.path.join(save_dir, 'Xpatchtst', '20260119')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lookback = 52\n",
    "horizon = 27\n",
    "batch_size = 256\n",
    "freq = 'weekly'\n",
    "split_mode = 'multi'\n",
    "shuffle = True\n",
    "id_col = 'unique_id'\n",
    "date_col = 'date'\n",
    "y_col = 'y'\n",
    "\n",
    "# add past exogenous continuous variable columns\n",
    "past_exo_cont_cols = (\n",
    "    # \"exo_p_y_lag_1w\",\n",
    "    \"exo_p_y_lag_2w\",\n",
    "    # \"exo_p_y_lag_52w\",\n",
    "    \"exo_p_y_rollmean_4w\",\"exo_p_y_rollmean_12w\",\"exo_p_y_rollstd_4w\",\n",
    "    # \"exo_p_weeks_since_holiday\",\n",
    "    # \"exo_p_temperature\",\n",
    "    # \"exo_p_fuel_price\",\n",
    "    # \"exo_p_cpi\",\n",
    "    # \"exo_p_unemployment\",\n",
    "    # \"exo_p_markdown_sum\",\n",
    "    # \"exo_p_markdown1\",\n",
    "    # \"exo_p_markdown2\",\n",
    "    # \"exo_p_markdown3\",\n",
    "    # \"exo_p_markdown4\",\n",
    "    # \"exo_p_markdown5\",\n",
    "    # \"exo_markdown1_isnull\",\n",
    "    # \"exo_markdown2_isnull\",\n",
    "    # \"exo_markdown3_isnull\",\n",
    "    # \"exo_markdown4_isnull\",\n",
    "    # \"exo_markdown5_isnull\",\n",
    ")\n",
    "\n",
    "# add past exogenous categorical variable columns\n",
    "past_exo_cat_cols = (\n",
    "    # \"exo_c_woy_bucket\",\n",
    ")\n",
    "\n",
    "future_exo_cb = None\n",
    "\n",
    "# real dataframe\n",
    "df = pl.read_parquet(dir + 'train_data/walmart_best_feature_train.parquet')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T03:57:39.204680Z",
     "start_time": "2026-01-19T03:57:22.345630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling_module.training.model_trainers.total_train import run_total_train_weekly\n",
    "from modeling_module.data_loader import MultiPartExoDataModule\n",
    "\n",
    "def inspect(loader, name):\n",
    "    b = next(iter(loader))\n",
    "    x, y, uid, fe, pe_cont, pe_cat = b\n",
    "    print(f\"[{name}] x:\", x.shape, x.device, x.dtype)\n",
    "    print(f\"[{name}] fe:\", fe.shape, fe.device, fe.dtype)\n",
    "    print(f\"[{name}] pe:\", pe_cont.shape, pe_cont.device, pe_cont.dtype)\n",
    "    print(f\"[{name}] future_exo_cb is None?\", loader.collate_fn.future_exo_cb is None)\n",
    "    if fe.shape[-1] > 0:\n",
    "        print(f\"[{name}] fe sample:\", fe[0, :3, :])\n",
    "\n",
    "data_module = MultiPartExoDataModule(\n",
    "    df = df,\n",
    "    id_col = id_col,\n",
    "    date_col = date_col,\n",
    "    y_col = y_col,\n",
    "    lookback = lookback,\n",
    "    horizon = horizon,\n",
    "    batch_size = batch_size,\n",
    "    past_exo_cont_cols = past_exo_cont_cols,\n",
    "    past_exo_cat_cols = past_exo_cat_cols,\n",
    "    future_exo_cb = future_exo_cb,\n",
    "    freq = freq,\n",
    "    shuffle = shuffle,\n",
    "    split_mode = split_mode,\n",
    ")\n",
    "\n",
    "train_loader = data_module.get_train_loader()\n",
    "val_loader = data_module.get_val_loader()\n",
    "\n",
    "inspect(train_loader, 'train_loader')\n",
    "\n",
    "run_total_train_weekly(\n",
    "    train_loader, val_loader, device = device,\n",
    "    lookback = lookback, horizon = horizon,\n",
    "    warmup_epochs = 30, spike_epochs = 0,\n",
    "    save_dir = save_root,\n",
    "    use_exogenous_mode = False,\n",
    "    models_to_run = ['patchmixer'], use_ssl_pretrain = False\n",
    ")"
   ],
   "id": "df3e41f811589d99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_loader] x: torch.Size([256, 52, 1]) cpu torch.float32\n",
      "[train_loader] fe: torch.Size([256, 27, 0]) cpu torch.float32\n",
      "[train_loader] pe: torch.Size([256, 52, 4]) cpu torch.float32\n",
      "[train_loader] future_exo_cb is None? True\n",
      "\n",
      "[total_train] === RUN: patchmixer (weekly) ===\n",
      "PatchMixer Base (Weekly)\n",
      "[EXO-setup] inferred E=0, model.exo_dim=0, has_head=False\n",
      "\n",
      "[train_patchmixer] ===== Stage 1/2 =====\n",
      "  - spike: OFF\n",
      "  - epochs: 30 | lr=0.0003 | horizon_decay=False\n",
      "[train_patchmixer] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 30,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 30,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "Epoch 1/30 | LR 0.000300 | Train 20224274432.000000 | Val 7158973269.333333\n",
      "Epoch 2/30 | LR 0.000298 | Train 11063700423.111111 | Val 5371949056.000000\n",
      "Epoch 3/30 | LR 0.000296 | Train 7928308736.000000 | Val 3953891733.333333\n",
      "Epoch 4/30 | LR 0.000293 | Train 6283763996.444445 | Val 2586985344.000000\n",
      "Epoch 5/30 | LR 0.000289 | Train 5517756131.555555 | Val 1361943850.666667\n",
      "Epoch 6/30 | LR 0.000284 | Train 4827882154.666667 | Val 2843395946.666667\n",
      "Epoch 7/30 | LR 0.000278 | Train 4534196167.111111 | Val 1237678069.333333\n",
      "Epoch 8/30 | LR 0.000271 | Train 4342606734.222222 | Val 1158934346.666667\n",
      "Epoch 9/30 | LR 0.000264 | Train 4132530375.111111 | Val 2351683466.666667\n",
      "Epoch 10/30 | LR 0.000256 | Train 3876470129.777778 | Val 1174228821.333333\n",
      "Epoch 11/30 | LR 0.000247 | Train 3760321564.444445 | Val 1685461280.000000\n",
      "Epoch 12/30 | LR 0.000238 | Train 3635060992.000000 | Val 1409912522.666667\n",
      "Epoch 13/30 | LR 0.000228 | Train 3507793208.888889 | Val 1456346208.000000\n",
      "Epoch 14/30 | LR 0.000218 | Train 3414693916.444445 | Val 1015318528.000000\n",
      "Epoch 15/30 | LR 0.000207 | Train 3312026140.444445 | Val 1496064341.333333\n",
      "Epoch 16/30 | LR 0.000196 | Train 3263196643.555555 | Val 709301328.000000\n",
      "Epoch 17/30 | LR 0.000185 | Train 3117392014.222222 | Val 1559378442.666667\n",
      "Epoch 18/30 | LR 0.000173 | Train 3045078499.555555 | Val 959232826.666667\n",
      "Epoch 19/30 | LR 0.000162 | Train 3070389788.444445 | Val 1047114736.000000\n",
      "Epoch 20/30 | LR 0.000150 | Train 3003098197.333333 | Val 1411122229.333333\n",
      "Epoch 21/30 | LR 0.000138 | Train 2929701120.000000 | Val 1568567680.000000\n",
      "Epoch 22/30 | LR 0.000127 | Train 2968668160.000000 | Val 1523301066.666667\n",
      "Epoch 23/30 | LR 0.000115 | Train 2899399168.000000 | Val 1183007322.666667\n",
      "Epoch 24/30 | LR 0.000104 | Train 2779899847.111111 | Val 1047125984.000000\n",
      "Epoch 25/30 | LR 0.000093 | Train 2770075619.555555 | Val 920451594.666667\n",
      "Epoch 26/30 | LR 0.000082 | Train 2777319253.333333 | Val 889706165.333333\n",
      "Epoch 27/30 | LR 0.000072 | Train 2768427804.444445 | Val 1068431370.666667\n",
      "Epoch 28/30 | LR 0.000062 | Train 2693319907.555555 | Val 1304502736.000000\n",
      "Epoch 29/30 | LR 0.000053 | Train 2714590890.666667 | Val 1262948528.000000\n",
      "Epoch 30/30 | LR 0.000044 | Train 2712757589.333333 | Val 902455146.666667\n",
      "\n",
      "[train_patchmixer] ===== Stage 2/2 =====\n",
      "  - spike: ON\n",
      "  - epochs: 0 | lr=9.999999999999999e-05 | horizon_decay=True\n",
      "[train_patchmixer] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 0,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 0,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[EXO-train] model.exo_dim=0  future_exo_cb? False  exo_is_normalized=True\n",
      "BaseModel(\n",
      "  (backbone): PatchMixerBackbone(\n",
      "    (padding_patch_layer): ReplicationPad1d((0, 8))\n",
      "    (blocks): ModuleList(\n",
      "      (0-2): 3 x PatchMixerLayer(\n",
      "        (token_mixer): Sequential(\n",
      "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), groups=64)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (channel_mixer): Sequential(\n",
      "          (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (W_P): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "  )\n",
      "  (z_proj): Identity()\n",
      "  (expander): TemporalExpander(\n",
      "    (time_bias): Sequential(\n",
      "      (0): Linear(in_features=480, out_features=448, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=448, out_features=448, bias=True)\n",
      "    )\n",
      "    (film): Sequential(\n",
      "      (0): Linear(in_features=480, out_features=896, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=896, out_features=896, bias=True)\n",
      "    )\n",
      "    (proj): Sequential(\n",
      "      (0): Linear(in_features=448, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dw): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "    (pw): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (revin): RevIN()\n",
      "  (base_head_b): Linear(in_features=448, out_features=1, bias=True)\n",
      "  (base_head_m): Linear(in_features=448, out_features=1, bias=True)\n",
      "  (base_gate): Linear(in_features=448, out_features=1, bias=True)\n",
      "  (pre_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (gate_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (gate_conv_3): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (gate_conv_5): Conv1d(128, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (gate_conv_d3): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "  (gate_reduce): Conv1d(96, 1, kernel_size=(1,), stride=(1,))\n",
      "  (gate_act): GELU(approximate='none')\n",
      "  (gate_do): Dropout(p=0.1, inplace=False)\n",
      "  (dw_head): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (z_align): Linear(in_features=448, out_features=448, bias=False)\n",
      "  (_z_exo_proj): Linear(in_features=4, out_features=448, bias=True)\n",
      "  (_z_gate): Linear(in_features=448, out_features=448, bias=True)\n",
      ") save success! C:\\Users\\USER\\PycharmProjects\\ts_forecaster_lib\\raw_data\\fit\\Xpatchtst\\20260119\\weekly_PatchMixerBase_L52_H27.pt\n",
      "PatchMixer Quantile (Weekly)\n",
      "[EXO-setup] inferred E=0, model.exo_dim=0, has_head=False\n",
      "\n",
      "[train_patchmixer] ===== Stage 1/2 =====\n",
      "  - spike: OFF\n",
      "  - epochs: 30 | lr=0.0003 | horizon_decay=False\n",
      "[train_patchmixer] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 30,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 20,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"quantile\",\n",
      "  \"point_loss\": \"mse\",\n",
      "  \"huber_delta\": 5.0,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 1.2,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.6,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 30,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 20,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"quantile\",\n",
      "  \"point_loss\": \"mse\",\n",
      "  \"huber_delta\": 5.0,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 1.2,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.6,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "Epoch 1/30 | LR 0.000300 | Train 17158783374.222221 | Val 19677776298.666668\n",
      "Epoch 2/30 | LR 0.000298 | Train 7227005354.666667 | Val 446028341.333333\n",
      "Epoch 3/30 | LR 0.000296 | Train 2791811925.333333 | Val 313657008.000000\n",
      "Epoch 4/30 | LR 0.000293 | Train 5711282403.555555 | Val 457818920.000000\n",
      "Epoch 5/30 | LR 0.000289 | Train 4957165212.444445 | Val 589971341.333333\n",
      "Epoch 6/30 | LR 0.000284 | Train 6292428913.777778 | Val 42350674.666667\n",
      "Epoch 7/30 | LR 0.000278 | Train 3267480277.333333 | Val 1026082218.666667\n",
      "Epoch 8/30 | LR 0.000271 | Train 1799184042.666667 | Val 118313990.666667\n",
      "Epoch 9/30 | LR 0.000264 | Train 1767574769.777778 | Val 1307198442.666667\n",
      "Epoch 10/30 | LR 0.000256 | Train 1795448618.666667 | Val 175062224.000000\n",
      "Epoch 11/30 | LR 0.000247 | Train 1460510904.888889 | Val 1300273242.666667\n",
      "Epoch 12/30 | LR 0.000238 | Train 1465918520.888889 | Val 115064639.333333\n",
      "Epoch 13/30 | LR 0.000228 | Train 1292496554.666667 | Val 801486965.333333\n",
      "Epoch 14/30 | LR 0.000218 | Train 1174771000.888889 | Val 87117656.000000\n",
      "Epoch 15/30 | LR 0.000207 | Train 1156839054.222222 | Val 566941184.000000\n",
      "Epoch 16/30 | LR 0.000196 | Train 1024808156.444444 | Val 78686489.333333\n",
      "Epoch 17/30 | LR 0.000185 | Train 1050866439.111111 | Val 376587986.666667\n",
      "Epoch 18/30 | LR 0.000173 | Train 888258816.000000 | Val 62657410.333333\n",
      "Epoch 19/30 | LR 0.000162 | Train 859968760.888889 | Val 354986237.333333\n",
      "Epoch 20/30 | LR 0.000150 | Train 751439388.444444 | Val 63610774.666667\n",
      "Epoch 21/30 | LR 0.000138 | Train 721423537.777778 | Val 323973546.666667\n",
      "Epoch 22/30 | LR 0.000127 | Train 682676778.666667 | Val 82821308.000000\n",
      "Epoch 23/30 | LR 0.000115 | Train 614240711.111111 | Val 273068409.333333\n",
      "Epoch 24/30 | LR 0.000104 | Train 582341048.888889 | Val 47415729.000000\n",
      "Epoch 25/30 | LR 0.000093 | Train 563123285.333333 | Val 244252238.666667\n",
      "Early stopping at epoch 26\n",
      "\n",
      "[train_patchmixer] ===== Stage 2/2 =====\n",
      "  - spike: ON\n",
      "  - epochs: 0 | lr=9.999999999999999e-05 | horizon_decay=True\n",
      "[train_patchmixer] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 0,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 20,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"quantile\",\n",
      "  \"point_loss\": \"mse\",\n",
      "  \"huber_delta\": 5.0,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 1.2,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.6,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 0,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 20,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"quantile\",\n",
      "  \"point_loss\": \"mse\",\n",
      "  \"huber_delta\": 5.0,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 1.2,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.6,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[EXO-train] model.exo_dim=0  future_exo_cb? False  exo_is_normalized=True\n",
      "QuantileModel(\n",
      "  (backbone): MultiScalePatchMixerBackbone(\n",
      "    (branches): ModuleList(\n",
      "      (0): PatchMixerBackbone(\n",
      "        (padding_patch_layer): ReplicationPad1d((0, 6))\n",
      "        (blocks): ModuleList(\n",
      "          (0-2): 3 x PatchMixerLayer(\n",
      "            (token_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (channel_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.02, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (W_P): Linear(in_features=13, out_features=64, bias=True)\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "      )\n",
      "      (1): PatchMixerBackbone(\n",
      "        (padding_patch_layer): ReplicationPad1d((0, 13))\n",
      "        (blocks): ModuleList(\n",
      "          (0-2): 3 x PatchMixerLayer(\n",
      "            (token_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), groups=64)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (channel_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.02, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (W_P): Linear(in_features=26, out_features=64, bias=True)\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "      )\n",
      "      (2): PatchMixerBackbone(\n",
      "        (padding_patch_layer): ReplicationPad1d((0, 19))\n",
      "        (blocks): ModuleList(\n",
      "          (0-2): 3 x PatchMixerLayer(\n",
      "            (token_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), groups=64)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (channel_mixer): Sequential(\n",
      "              (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.02, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (W_P): Linear(in_features=39, out_features=64, bias=True)\n",
      "        (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "      )\n",
      "    )\n",
      "    (projs): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "    (fuse): Linear(in_features=192, out_features=128, bias=True)\n",
      "  )\n",
      "  (z_proj): Identity()\n",
      "  (expander): TemporalExpander(\n",
      "    (time_bias): Sequential(\n",
      "      (0): Linear(in_features=160, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (film): Sequential(\n",
      "      (0): Linear(in_features=160, out_features=256, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (proj): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dw): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "    (pw): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): DecompositionQuantileHead(\n",
      "    (core): DecompositionQuantileHeadCore(\n",
      "      (feat_proj): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.02, inplace=False)\n",
      "      )\n",
      "      (mid_head): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "      )\n",
      "      (trend_head): Linear(in_features=128, out_features=2, bias=True)\n",
      "      (irreg_head): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (season_time_head): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "      )\n",
      "      (delta_head): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (revin): RevIN()\n",
      "  (z_align): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (_z_exo_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (_z_gate): Linear(in_features=128, out_features=128, bias=True)\n",
      ") save success! C:\\Users\\USER\\PycharmProjects\\ts_forecaster_lib\\raw_data\\fit\\Xpatchtst\\20260119\\weekly_PatchMixerQuantile_L52_H27.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PatchMixer Base': {'model': BaseModel(\n",
       "    (backbone): PatchMixerBackbone(\n",
       "      (padding_patch_layer): ReplicationPad1d((0, 8))\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x PatchMixerLayer(\n",
       "          (token_mixer): Sequential(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), groups=64)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (channel_mixer): Sequential(\n",
       "            (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (W_P): Linear(in_features=12, out_features=64, bias=True)\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    )\n",
       "    (z_proj): Identity()\n",
       "    (expander): TemporalExpander(\n",
       "      (time_bias): Sequential(\n",
       "        (0): Linear(in_features=480, out_features=448, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=448, out_features=448, bias=True)\n",
       "      )\n",
       "      (film): Sequential(\n",
       "        (0): Linear(in_features=480, out_features=896, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=896, out_features=896, bias=True)\n",
       "      )\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=448, out_features=128, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (dw): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "      (pw): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (revin): RevIN()\n",
       "    (base_head_b): Linear(in_features=448, out_features=1, bias=True)\n",
       "    (base_head_m): Linear(in_features=448, out_features=1, bias=True)\n",
       "    (base_gate): Linear(in_features=448, out_features=1, bias=True)\n",
       "    (pre_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (gate_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (gate_conv_3): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (gate_conv_5): Conv1d(128, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (gate_conv_d3): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (gate_reduce): Conv1d(96, 1, kernel_size=(1,), stride=(1,))\n",
       "    (gate_act): GELU(approximate='none')\n",
       "    (gate_do): Dropout(p=0.1, inplace=False)\n",
       "    (dw_head): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (z_align): Linear(in_features=448, out_features=448, bias=False)\n",
       "    (_z_exo_proj): Linear(in_features=4, out_features=448, bias=True)\n",
       "    (_z_gate): Linear(in_features=448, out_features=448, bias=True)\n",
       "  ),\n",
       "  'cfg': TrainingConfig(device='cuda', log_every=100, use_amp=True, lookback=52, horizon=27, epochs=0, lr=9.999999999999999e-05, weight_decay=0.001, t_max=40, patience=100, max_grad_norm=30.0, amp_device='cuda', loss_mode='point', point_loss='huber', huber_delta=0.8, q_star=0.5, use_cost_q_star=False, Cu=1.0, Co=1.0, quantiles=(0.1, 0.5, 0.9), use_intermittent=True, alpha_zero=3.0, alpha_pos=1.0, gamma_run=0.3, cap=None, use_horizon_decay=True, tau_h=0.85, val_use_weights=False, spike_loss=SpikeLossConfig(enabled=True, strategy='mix', huber_delta=0.6, asym_up_weight=1.0, asym_down_weight=2.0, mad_k=1.5, w_spike=4.0, w_norm=1.0, alpha_huber=0.6, beta_asym=0.4, mix_with_baseline=False, gamma_baseline=0.0), lambda_hist_scale=0.1, lambda_hist_var=0.03, hist_window=12, anchor_last_k=8, anchor_weight=0.05),\n",
       "  'ckpt_path': 'C:\\\\Users\\\\USER\\\\PycharmProjects\\\\ts_forecaster_lib\\\\raw_data\\\\fit\\\\Xpatchtst\\\\20260119\\\\weekly_PatchMixerBase_L52_H27.pt'},\n",
       " 'PatchMixer Quantile': {'model': QuantileModel(\n",
       "    (backbone): MultiScalePatchMixerBackbone(\n",
       "      (branches): ModuleList(\n",
       "        (0): PatchMixerBackbone(\n",
       "          (padding_patch_layer): ReplicationPad1d((0, 6))\n",
       "          (blocks): ModuleList(\n",
       "            (0-2): 3 x PatchMixerLayer(\n",
       "              (token_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (channel_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.02, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (W_P): Linear(in_features=13, out_features=64, bias=True)\n",
       "          (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "        )\n",
       "        (1): PatchMixerBackbone(\n",
       "          (padding_patch_layer): ReplicationPad1d((0, 13))\n",
       "          (blocks): ModuleList(\n",
       "            (0-2): 3 x PatchMixerLayer(\n",
       "              (token_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), groups=64)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (channel_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.02, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (W_P): Linear(in_features=26, out_features=64, bias=True)\n",
       "          (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "        )\n",
       "        (2): PatchMixerBackbone(\n",
       "          (padding_patch_layer): ReplicationPad1d((0, 19))\n",
       "          (blocks): ModuleList(\n",
       "            (0-2): 3 x PatchMixerLayer(\n",
       "              (token_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), groups=64)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (channel_mixer): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.02, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (W_P): Linear(in_features=39, out_features=64, bias=True)\n",
       "          (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (projs): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (fuse): Linear(in_features=192, out_features=128, bias=True)\n",
       "    )\n",
       "    (z_proj): Identity()\n",
       "    (expander): TemporalExpander(\n",
       "      (time_bias): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=128, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (film): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (dw): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
       "      (pw): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (head): DecompositionQuantileHead(\n",
       "      (core): DecompositionQuantileHeadCore(\n",
       "        (feat_proj): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.02, inplace=False)\n",
       "        )\n",
       "        (mid_head): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "        )\n",
       "        (trend_head): Linear(in_features=128, out_features=2, bias=True)\n",
       "        (irreg_head): Linear(in_features=128, out_features=1, bias=True)\n",
       "        (season_time_head): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        )\n",
       "        (delta_head): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (revin): RevIN()\n",
       "    (z_align): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (_z_exo_proj): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (_z_gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  ),\n",
       "  'cfg': TrainingConfig(device='cuda', log_every=100, use_amp=True, lookback=52, horizon=27, epochs=0, lr=9.999999999999999e-05, weight_decay=0.0001, t_max=40, patience=20, max_grad_norm=30.0, amp_device='cuda', loss_mode='quantile', point_loss='mse', huber_delta=5.0, q_star=0.5, use_cost_q_star=False, Cu=1.0, Co=1.0, quantiles=(0.1, 0.5, 0.9), use_intermittent=True, alpha_zero=1.2, alpha_pos=1.0, gamma_run=0.6, cap=None, use_horizon_decay=True, tau_h=0.85, val_use_weights=False, spike_loss=SpikeLossConfig(enabled=True, strategy='mix', huber_delta=0.6, asym_up_weight=1.0, asym_down_weight=2.0, mad_k=1.5, w_spike=4.0, w_norm=1.0, alpha_huber=0.6, beta_asym=0.4, mix_with_baseline=False, gamma_baseline=0.0), lambda_hist_scale=0.1, lambda_hist_var=0.03, hist_window=12, anchor_last_k=8, anchor_weight=0.05),\n",
       "  'ckpt_path': 'C:\\\\Users\\\\USER\\\\PycharmProjects\\\\ts_forecaster_lib\\\\raw_data\\\\fit\\\\Xpatchtst\\\\20260119\\\\weekly_PatchMixerQuantile_L52_H27.pt'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "43b0964a9129cee8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

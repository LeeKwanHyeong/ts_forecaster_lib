{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.143456Z",
     "start_time": "2025-10-28T12:22:10.002064Z"
    }
   },
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "MAC_DIR = '/Users/igwanhyeong/PycharmProjects/data_research/raw_data/'\n",
    "\n",
    "A_dict = {\n",
    "    'oper_part_no': ['A' for _ in range(8)],\n",
    "    'demand_dt': [i for i in range(202401, 202409)],\n",
    "    'demand_qty': [float(i) for i in range(8)],\n",
    "    'gbm_cd': ['VD' for _ in range(8)]\n",
    "}\n",
    "\n",
    "A_pl = pl.DataFrame(A_dict)\n",
    "\n",
    "B_dict = {\n",
    "    'oper_part_no': ['B' for _ in range(8)],\n",
    "    'demand_dt': [i for i in range(202501, 202509)],\n",
    "    'demand_qty': [float(i) for i in range(8)],\n",
    "    'gbm_cd': ['VD' for _ in range(8)]\n",
    "}\n",
    "B_pl = pl.DataFrame(B_dict)\n",
    "\n",
    "\n",
    "target_dyn_demand_monthly = pl.read_parquet(MAC_DIR + 'target_dyn_demand_monthly.parquet').with_columns(pl.lit('VD').alias('gbm_cd'))\n",
    "df = pl.concat([target_dyn_demand_monthly, A_pl, B_pl])\n",
    "\n",
    "df = df.rename({'oper_part_no': 'part_no', 'demand_dt': 'yyyymm', 'demand_qty': 'qty'})"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.179379Z",
     "start_time": "2025-10-28T12:22:10.147008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keys = df.select('gbm_cd').unique().to_series().to_list()\n",
    "frames = df.partition_by('gbm_cd', maintain_order = True)\n",
    "by_bu = dict(zip(keys, frames))"
   ],
   "id": "5248c2844057cac1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.186239Z",
     "start_time": "2025-10-28T12:22:10.182839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ltb/forecasting/short_series/policy_config.py\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ShortSeriesPolicyConfig:\n",
    "    history_threshold: int = 6               # 6 미만이면 ShortSeries 라우팅\n",
    "    donor_k: int = 5                         # 유사 도너 개수\n",
    "    donor_min_k: int = 3                     # 최소 확보 도너 개수\n",
    "    donor_same_group_only: bool = True       # 같은 그룹(BU/카테고리 등)에서만 도너 탐색\n",
    "\n",
    "    # 계층 점유율(share) EMA + 수축\n",
    "    share_lambda: float = 0.7                # EMA 가중치 (0.6~0.8 권장)\n",
    "    share_floor: float = 0.0                 # 점유율 하한\n",
    "    share_ceil: float = 1.0                  # 점유율 상한\n",
    "\n",
    "    # 글로벌 풀링 베이스라인(간이 Theta/감쇠 추세)\n",
    "    damped_r_min: float = 0.85\n",
    "    damped_r_max: float = 0.98\n",
    "\n",
    "    # 가드레일/윈저라이즈\n",
    "    max_step_up: float = 0.10                # +10%\n",
    "    max_step_down: float = 0.40              # -40%\n",
    "    winsor_q_low: float = 0.05\n",
    "    winsor_q_high: float = 0.95\n",
    "    winsor_mul: float = 4.0\n",
    "    winsor_growth: float = 3.0               # 비정상 증가 억제 계수\n",
    "    floor_qty: float = 0.0                   # 의무보유/최소 수요 하한 (있으면 설정)\n",
    "\n",
    "    # 정량화(불확실성) 기본\n",
    "    quantiles: tuple = (0.1, 0.5, 0.9)\n",
    "\n",
    "    # 기타\n",
    "    random_state: Optional[int] = 42"
   ],
   "id": "99e6f8dac5a8e378",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.194937Z",
     "start_time": "2025-10-28T12:22:10.188837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "donor_bank.py\n",
    "'''\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class Donor:\n",
    "    group_id: str\n",
    "    series: np.ndarray # 전체 시계열 (길이 >= 5 권장)\n",
    "\n",
    "class DonorBank:\n",
    "    def __init__(self, donors: List[Donor]) -> None:\n",
    "        self.donors = donors\n",
    "\n",
    "    @staticmethod\n",
    "    def _best_k_windows(target_5: np.ndarray, donor_series: np.ndarray, k: int) -> Tuple[List[int], List[float]]:\n",
    "        L = len(donor_series)\n",
    "        if L < 9:\n",
    "            return [], []\n",
    "\n",
    "        scores = []\n",
    "        idxs = []\n",
    "        for start in range(0, L - 9):\n",
    "            window = donor_series[start: start + 9]\n",
    "            if np.std(window) == 0 or np.std(target_5) == 0:\n",
    "                corr = 0.0\n",
    "            else:\n",
    "                corr = float(np.corrcoef(target_5, window)[0, 1])\n",
    "\n",
    "            idxs. append(start)\n",
    "            scores.append(corr)\n",
    "\n",
    "        order = np.argsort(scores)[::-1][:k]\n",
    "        return [idxs[i] for i in order], [scores[i] for i in order]\n",
    "\n",
    "    def find_analogs(\n",
    "            self,\n",
    "            target_5: np.ndarray,\n",
    "            meta: Dict[str, Any],\n",
    "            k: int = 5,\n",
    "            same_group_only: bool = True\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        group_id = meta.get('group_id', None)\n",
    "        candidates = [d for d in self.donors if (not same_group_only) or (d.group_id == group_id)]\n",
    "\n",
    "        matches = []\n",
    "        for d in candidates:\n",
    "            idxs, scores = self._best_k_windows(target_5, d.series, k = 1)\n",
    "            if not idxs:\n",
    "                continue\n",
    "            start = idxs[0]\n",
    "            score = scores[0]\n",
    "\n",
    "            matches.append({\n",
    "                'group_id': d.group_id,\n",
    "                'series': d.series,\n",
    "                'start': start,\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "        matches = sorted(matches, key = lambda k: k['score'], reverse = True)[:k]\n",
    "        return matches\n",
    "\n",
    "    @staticmethod\n",
    "    def analog_transfer(\n",
    "            target_5: np.ndarray,\n",
    "            matches: List[Dict[str, Any]],\n",
    "            horizon: int,\n",
    "            scale_mode: str = 'last2_mean'\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if not matches:\n",
    "            return np.array([]), np.empty((0, horizon))\n",
    "\n",
    "        donor_preds = []\n",
    "        for m in matches:\n",
    "            ds = m['series']\n",
    "            st = m['start']\n",
    "            future = ds[st+9: st+9+horizon]\n",
    "            if len(future) < horizon:\n",
    "                if len(future) == 0:\n",
    "                    future = np.zeros(horizon, dtype=float)\n",
    "                else:\n",
    "                    last = future[-1]\n",
    "                    future = np.concatenate([future, np.full(horizon - len(future), last, dtype = float)])\n",
    "            donor_preds.append(future)\n",
    "        donor_stack = np.vstack(donor_preds)\n",
    "\n",
    "        if scale_mode == 'last2_mean':\n",
    "            t_mean = float(np.mean(target_5[-2:])) if np.any(target_5[-2:]) else float(np.mean(target_5))\n",
    "            d_means = np.mean(donor_stack[:, :2], axis = 1)\n",
    "            d_mean = float(np.mean(d_means)) if np.any(d_means) else max(float(np.mean(donor_stack[:, :2])), 1e-6)\n",
    "            s = t_mean / max(d_mean, 1e-6)\n",
    "        else:\n",
    "            s = 1.0\n",
    "\n",
    "        y_hat = s * np.mean(donor_stack, axis = 0)\n",
    "        return y_hat, donor_stack"
   ],
   "id": "1c61e91d13c3ecee",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.201274Z",
     "start_time": "2025-10-28T12:22:10.199168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "hierarchical_allocate.py\n",
    "'''\n",
    "\n",
    "def ema_shrunk_share(last_share: float, group_mean_share: float, lam: float) -> float:\n",
    "    s = lam * float(last_share) + (1.0 - lam) * float(group_mean_share)\n",
    "    return float(np.clip(s, 0.0, 1.0))\n",
    "\n",
    "def allocate_from_group_forecast(\n",
    "        group_forecast: np.ndarray,\n",
    "        last_share: float,\n",
    "        group_mean_share: float,\n",
    "        lam: float,\n",
    "        floor: float = 0.0,\n",
    "        ceil: float = 1.0\n",
    ") -> np.ndarray:\n",
    "    s_next = ema_shrunk_share(last_share, group_mean_share, lam)\n",
    "    s_next = float(np.clip(s_next, floor, ceil))\n",
    "    return s_next"
   ],
   "id": "5d7bbb767a39bf9a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.511522Z",
     "start_time": "2025-10-28T12:22:10.203814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# yyyymm <-> (year, month) 변환과 월 더하기\n",
    "def split_yyyymm(yyyymm: int) -> tuple[int, int]:\n",
    "    return yyyymm // 100, yyyymm % 100\n",
    "\n",
    "def join_yyyymm(year: int, month: int) -> int:\n",
    "    return year * 100 + month\n",
    "\n",
    "def add_months_yyyymm(yyyymm: int, k: int) -> int:\n",
    "    y, m = split_yyyymm(yyyymm)\n",
    "    m_new = m + k\n",
    "    y += (m_new - 1) // 12\n",
    "    m = ((m_new - 1) % 12) + 1\n",
    "    return join_yyyymm(y, m)\n",
    "\n",
    "def month_range_yyyymm(start_yyyymm: int, end_yyyymm: int) -> list[int]:\n",
    "    # start <= ... <= end 포함 범위\n",
    "    out = []\n",
    "    cur = start_yyyymm\n",
    "    while cur <= end_yyyymm:\n",
    "        out.append(cur)\n",
    "        cur = add_months_yyyymm(cur, 1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fill_missing_months_per_part(df_bu: pl.DataFrame) -> pl.DataFrame:\n",
    "    # 사업부 전체 yyyymm 범위\n",
    "    bounds = df_bu.select(\n",
    "        pl.col(\"yyyymm\").min().alias(\"min_ym\"),\n",
    "        pl.col(\"yyyymm\").max().alias(\"max_ym\")\n",
    "    ).row(0)\n",
    "    min_ym, max_ym = int(bounds[0]), int(bounds[1])\n",
    "\n",
    "    full_months = month_range_yyyymm(min_ym, max_ym)  # 이전에 정의한 유틸\n",
    "    months_df = pl.DataFrame({\"yyyymm\": full_months})\n",
    "\n",
    "    parts_df = df_bu.select(\"part_no\").unique()\n",
    "\n",
    "    # part_no × yyyymm 전체 격자\n",
    "    full_idx = parts_df.join(months_df, how=\"cross\")\n",
    "\n",
    "    # 원본을 LEFT JOIN 후 결측 0 채움\n",
    "    filled = (\n",
    "        full_idx.join(\n",
    "            df_bu.select(\"part_no\", \"yyyymm\", \"qty\"),\n",
    "            on=[\"part_no\", \"yyyymm\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .with_columns(pl.col(\"qty\").fill_null(0.0))\n",
    "        .sort([\"part_no\", \"yyyymm\"])\n",
    "    )\n",
    "    return filled\n",
    "\n",
    "filled_by_bu = {bu: fill_missing_months_per_part(df_bu) for bu, df_bu in by_bu.items()}"
   ],
   "id": "963d6d6fb936f1fb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.520264Z",
     "start_time": "2025-10-28T12:22:10.517563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H = 120\n",
    "cfg = ShortSeriesPolicyConfig(\n",
    "    history_threshold = 6, donor_k = 5, donor_min_k = 3,\n",
    "    max_step_up = 0.10, max_step_down = 0.40,\n",
    "    winsor_q_low = 0.05, winsor_q_high = 0.95,\n",
    "    winsor_mul = 4.0, winsor_growth=3.0,\n",
    "    floor_qty = 0.0\n",
    ")\n",
    "\n",
    "\n",
    "# 해당 메서드에서 과연 len(series)를 >= 9 + H로 맞춰야 하는가?\n",
    "def build_donor_bank(df_bu_filled: pl.DataFrame, group_id: str) -> DonorBank:\n",
    "    donors = []\n",
    "    for pno, g in df_bu_filled.group_by('part_no'):\n",
    "        series = g.sort('yyyymm')['qty'].to_numpy()\n",
    "        if len(series) >= 9:\n",
    "            donors.append(Donor(group_id = group_id, series = series.astype(float)))\n",
    "    return DonorBank(donors)\n",
    "\n",
    "def build_group_series(df_bu_filled: pl.DataFrame) -> tuple[np.ndarray, list[int]]:\n",
    "    grp = (df_bu_filled.group_by('yyyymm')\n",
    "            .agg(pl.col('qty').sum().alias('qty'))\n",
    "            .sort('yyyymm')\n",
    "           )\n",
    "    return grp['qty'].to_numpy(), grp['yyyymm'].to_list()"
   ],
   "id": "fdf7cd90cdee47a7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.528132Z",
     "start_time": "2025-10-28T12:22:10.524808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 예측 월 계산(fcst_yyyymm)\n",
    "def forecast_months(last_yyyymm: int, H: int) -> list[int]:\n",
    "    return [add_months_yyyymm(last_yyyymm, i + 1) for i in range(H)]\n",
    "\n",
    "# 점유율 계산(동일 yyyymm 조인)\n",
    "def compute_shares_item_vs_group(item_tbl: pl.DataFrame, group_tbl: pl.DataFrame) -> np.ndarray:\n",
    "    j = (item_tbl\n",
    "         .join(group_tbl.rename({'qty': 'qty_grp'}), on = 'yyyymm', how = 'inner')\n",
    "         .select((pl.col('qty') / pl.col('qty_grp').clip(lower_bound = 1e-6)).alias('share'))\n",
    "         )\n",
    "    return j['share'].to_numpy()\n",
    "\n",
    "def simple_damped_trend_forecast(\n",
    "    history: np.ndarray,\n",
    "    horizon: int,\n",
    "    r: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    간이 Theta/감쇠 추세 대체:\n",
    "    - 레벨 L0 = 최근 2~3개월 평균\n",
    "    - 기울기 b = 최근 차분의 중앙값\n",
    "    - 감쇠 r (0.85~0.98)\n",
    "    \"\"\"\n",
    "    h = history.astype(float)\n",
    "    L0 = float(np.mean(h[-2:])) if len(h) >= 2 else float(np.mean(h))\n",
    "    diffs = np.diff(h) if len(h) >= 2 else np.array([0.0])\n",
    "    b = float(np.median(diffs)) if len(diffs) else 0.0\n",
    "\n",
    "    steps = np.arange(1, horizon + 1, dtype=float)\n",
    "    damp = (1.0 - np.power(r, steps)) / (1.0 - r)  # Σ r^i 형태\n",
    "    y = L0 + b * damp\n",
    "    return y\n",
    "\n",
    "def choose_r_by_group(r_min: float, r_max: float) -> float:\n",
    "    # 그룹별 에러프로파일에 따라 다르게 줄 수 있으나 스켈레톤에서는 중간값 사용\n",
    "    return (r_min + r_max) / 2.0"
   ],
   "id": "29bf64a4a4d7a40d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.536725Z",
     "start_time": "2025-10-28T12:22:10.531883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ltb/forecasting/short_series/guardrails.py\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def apply_step_caps(\n",
    "    y_hat: np.ndarray,\n",
    "    last_level: float,\n",
    "    max_step_up: float,\n",
    "    max_step_down: float\n",
    ") -> np.ndarray:\n",
    "    capped = []\n",
    "    prev = float(last_level)\n",
    "    for yh in y_hat:\n",
    "        up_bound = prev * (1.0 + max_step_up)\n",
    "        dn_bound = prev * (1.0 - max_step_down)\n",
    "        val = float(np.clip(yh, dn_bound, up_bound))\n",
    "        capped.append(val)\n",
    "        prev = val\n",
    "    return np.array(capped, dtype=float)\n",
    "\n",
    "def apply_winsor_and_floor(\n",
    "    y_hat: np.ndarray,\n",
    "    winsor_q: Tuple[float, float],\n",
    "    winsor_mul: float,\n",
    "    winsor_growth: float,\n",
    "    floor_qty: float\n",
    ") -> np.ndarray:\n",
    "    arr = y_hat.copy().astype(float)\n",
    "    if len(arr) >= 3:\n",
    "        q_low, q_high = np.quantile(arr, winsor_q)\n",
    "        iqr = q_high - q_low\n",
    "        lo = q_low - winsor_mul * iqr\n",
    "        hi = q_high + winsor_mul * iqr\n",
    "        arr = np.clip(arr, lo, hi)\n",
    "    # 과도한 성장 완충 (간단히 전 스텝 대비 winsor_growth 배 제한)\n",
    "    for i in range(1, len(arr)):\n",
    "        arr[i] = min(arr[i], arr[i-1] * winsor_growth)\n",
    "    if floor_qty is not None:\n",
    "        arr = np.maximum(arr, float(floor_qty))\n",
    "    return arr\n",
    "\n",
    "def quantiles_from_donors(\n",
    "    donor_stack: np.ndarray,\n",
    "    scale_factor: float = 1.0,\n",
    "    qs=(0.1, 0.5, 0.9)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    도너 기반 분포에서 분위수를 직접 계산\n",
    "    donor_stack: (K, H)\n",
    "    \"\"\"\n",
    "    if donor_stack.size == 0:\n",
    "        return {}\n",
    "    q_map = {}\n",
    "    for q in qs:\n",
    "        q_map[q] = scale_factor * np.quantile(donor_stack, q, axis=0)\n",
    "    return q_map\n",
    "\n",
    "def symmetric_quantile_fan(\n",
    "    median: np.ndarray,\n",
    "    spread_ratio: float = 0.3,  # 기본 확산 비율\n",
    "    qs=(0.1, 0.5, 0.9)\n",
    ") -> dict:\n",
    "    out = {}\n",
    "    for q in qs:\n",
    "        if q == 0.5:\n",
    "            out[q] = median\n",
    "        elif q < 0.5:\n",
    "            out[q] = np.maximum(0.0, median * (1.0 - spread_ratio))\n",
    "        else:\n",
    "            out[q] = median * (1.0 + spread_ratio)\n",
    "    return out"
   ],
   "id": "23a476040157a7e1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:10.544834Z",
     "start_time": "2025-10-28T12:22:10.539274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ltb/forecasting/short_series/short_series_forecaster.py\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "class ShortSeriesForecaster:\n",
    "    \"\"\"\n",
    "    라우팅 순서:\n",
    "      1) 도너 전이(충분 K 확보 시) → 도너 앙상블 예측\n",
    "      2) 그룹 예측(있다면) × 점유율(EMA+수축) → 배분\n",
    "      3) 글로벌 풀링 베이스라인(간이 Theta/감쇠)\n",
    "      4) 가드레일(스텝 캡/윈저/그로스 제한/플로어)\n",
    "      5) 분위수 산출(도너 기반 또는 대칭 팬)\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ShortSeriesPolicyConfig, donor_bank: DonorBank) -> None:\n",
    "        self.cfg = config\n",
    "        self.donor_bank = donor_bank\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        history: np.ndarray,               # shape: (T,)  T<=5\n",
    "        meta: Dict[str, Any],              # {'group_id', 'group_mean_share', 'last_share', ...}\n",
    "        horizon: int,\n",
    "        group_forecast: np.ndarray | None  # shape: (H,) or None\n",
    "    ) -> Dict[float, np.ndarray]:\n",
    "        assert history.ndim == 1, \"history must be 1D array\"\n",
    "        T = len(history)\n",
    "        assert T < self.cfg.history_threshold, \"history too long for ShortSeriesForecaster\"\n",
    "\n",
    "        # ---- 1) 도너 전이\n",
    "        y_donor = None\n",
    "        donor_stack = np.empty((0, horizon))\n",
    "        matches = self.donor_bank.find_analogs(\n",
    "            target_5=history,\n",
    "            meta=meta,\n",
    "            k=self.cfg.donor_k,\n",
    "            same_group_only=self.cfg.donor_same_group_only\n",
    "        )\n",
    "        if len(matches) >= self.cfg.donor_min_k:\n",
    "            y_donor, donor_stack = self.donor_bank.analog_transfer(\n",
    "                target_5=history,\n",
    "                matches=matches,\n",
    "                horizon=horizon\n",
    "            )\n",
    "\n",
    "        # ---- 2) 계층 배분\n",
    "        y_hier = None\n",
    "        if group_forecast is not None and \"last_share\" in meta and \"group_mean_share\" in meta:\n",
    "            y_hier = allocate_from_group_forecast(\n",
    "                group_forecast=group_forecast,\n",
    "                last_share=float(meta[\"last_share\"]),\n",
    "                group_mean_share=float(meta[\"group_mean_share\"]),\n",
    "                lam=self.cfg.share_lambda,\n",
    "                floor=self.cfg.share_floor,\n",
    "                ceil=self.cfg.share_ceil\n",
    "            )\n",
    "\n",
    "        # ---- 3) 글로벌 베이스라인\n",
    "        r = choose_r_by_group(self.cfg.damped_r_min, self.cfg.damped_r_max)\n",
    "        y_base = simple_damped_trend_forecast(history, horizon, r)\n",
    "\n",
    "        # ---- 4) 앙상블 결합 (간단 가중 합; 필요 시 메타학습으로 교체)\n",
    "        # 우선순위: 도너 > 계층 > 베이스라인\n",
    "        weights = []\n",
    "        candidates = []\n",
    "        if y_donor is not None and len(y_donor):\n",
    "            candidates.append(y_donor); weights.append(0.6)\n",
    "        if y_hier is not None:\n",
    "            candidates.append(y_hier);  weights.append(0.3)\n",
    "        candidates.append(y_base);      weights.append(0.1)\n",
    "\n",
    "        weights = np.array(weights, dtype=float)\n",
    "        weights = weights / weights.sum()\n",
    "        stacked = np.vstack(candidates)  # (n_comp, H)\n",
    "        y_hat = np.sum(stacked * weights[:, None], axis=0)\n",
    "\n",
    "        # ---- 5) 가드레일 적용\n",
    "        last_level = float(np.mean(history[-2:])) if len(history) >= 2 else float(history[-1])\n",
    "        y_hat = apply_step_caps(\n",
    "            y_hat, last_level,\n",
    "            max_step_up=self.cfg.max_step_up,\n",
    "            max_step_down=self.cfg.max_step_down\n",
    "        )\n",
    "        y_hat = apply_winsor_and_floor(\n",
    "            y_hat,\n",
    "            winsor_q=(self.cfg.winsor_q_low, self.cfg.winsor_q_high),\n",
    "            winsor_mul=self.cfg.winsor_mul,\n",
    "            winsor_growth=self.cfg.winsor_growth,\n",
    "            floor_qty=self.cfg.floor_qty\n",
    "        )\n",
    "\n",
    "        # ---- 6) 분위수 산출\n",
    "        if donor_stack.size > 0:\n",
    "            # 도너 분포 기반 분위수 + 가드레일 재적용\n",
    "            q_map = quantiles_from_donors(donor_stack, scale_factor=1.0, qs=self.cfg.quantiles)\n",
    "            # 중앙값을 최종 y_hat으로 치환\n",
    "            q_map[0.5] = y_hat\n",
    "            # 하/상 분위수도 같은 가드레일 적용(일관성)\n",
    "            for q in q_map:\n",
    "                q_map[q] = apply_step_caps(q_map[q], last_level, self.cfg.max_step_up, self.cfg.max_step_down)\n",
    "                q_map[q] = apply_winsor_and_floor(\n",
    "                    q_map[q],\n",
    "                    winsor_q=(self.cfg.winsor_q_low, self.cfg.winsor_q_high),\n",
    "                    winsor_mul=self.cfg.winsor_mul,\n",
    "                    winsor_growth=self.cfg.winsor_growth,\n",
    "                    floor_qty=self.cfg.floor_qty\n",
    "                )\n",
    "        else:\n",
    "            # 도너 없음 → 대칭 팬\n",
    "            q_map = symmetric_quantile_fan(y_hat, spread_ratio=0.3, qs=self.cfg.quantiles)\n",
    "\n",
    "        return q_map  # {0.1: np.ndarray(H,), 0.5: ..., 0.9: ...}"
   ],
   "id": "cc89ffb010244f5e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:22:58.809617Z",
     "start_time": "2025-10-28T12:22:10.547346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = []  # (gbm_cd, part_no, fcst_yyyymm, q10, q50, q90)\n",
    "\n",
    "for bu, df_bu in by_bu.items():\n",
    "    # 7-1) 결측월 채운 테이블\n",
    "    df_bu_filled = filled_by_bu[bu]\n",
    "\n",
    "    # 7-2) 그룹(사업부) 시계열 & 예측\n",
    "    group_s, group_months = build_group_series(df_bu_filled)\n",
    "    group_fcst = None\n",
    "    if len(group_s) >= 2:\n",
    "        r = choose_r_by_group(cfg.damped_r_min, cfg.damped_r_max)\n",
    "        group_fcst = simple_damped_trend_forecast(group_s, H, r)\n",
    "\n",
    "    # 7-3) fcst_yyyymm 생성\n",
    "    last_ym = max(group_months) if group_months else None\n",
    "    fcst_months = forecast_months(int(last_ym), H) if last_ym else [ ]\n",
    "\n",
    "    # 7-4) 도너 뱅크\n",
    "    donor_bank = build_donor_bank(df_bu_filled, group_id=bu)\n",
    "    ssf = ShortSeriesForecaster(cfg, donor_bank)\n",
    "\n",
    "    # 7-5) 그룹 합표(점유율용)\n",
    "    group_tbl = (df_bu_filled.group_by(\"yyyymm\")\n",
    "                 .agg(pl.col(\"qty\").sum().alias(\"qty\"))\n",
    "                 .sort(\"yyyymm\"))\n",
    "\n",
    "    # 7-6) 파트 예측\n",
    "    for pno, g in df_bu_filled.group_by(\"part_no\"):\n",
    "        item_tbl = g.sort(\"yyyymm\").select(\"yyyymm\", \"qty\")\n",
    "        history = item_tbl[\"qty\"].to_numpy()\n",
    "        T = len(history)\n",
    "\n",
    "        # 점유율 특징\n",
    "        shares = compute_shares_item_vs_group(item_tbl, group_tbl) if T > 0 else np.array([], float)\n",
    "        last_share = float(shares[-1]) if shares.size else 0.0\n",
    "        group_mean_share = float(np.mean(shares[-min(T, 6):])) if shares.size else 0.0\n",
    "\n",
    "        meta = {\"group_id\": bu, \"last_share\": last_share, \"group_mean_share\": group_mean_share}\n",
    "\n",
    "        if T < cfg.history_threshold:\n",
    "            q_map = ssf.forecast(history=history, meta=meta, horizon=H, group_forecast=group_fcst)\n",
    "            q10 = q_map.get(0.1); q50 = q_map.get(0.5); q90 = q_map.get(0.9)\n",
    "        else:\n",
    "            # 긴 항목은 기존 모델(예: PatchMixer/Titan)로 라우팅하십시오.\n",
    "            # 임시 대체: 그룹 예측 × 점유율(EMA 수축 전) 또는 감쇠 베이스라인\n",
    "            if group_fcst is not None:\n",
    "                y = group_fcst * (0.7 * last_share + 0.3 * group_mean_share)\n",
    "            else:\n",
    "                r = choose_r_by_group(cfg.damped_r_min, cfg.damped_r_max)\n",
    "                y = simple_damped_trend_forecast(history, H, r)\n",
    "            q10, q50, q90 = y * 0.8, y, y * 1.2\n",
    "\n",
    "        # 결과 수집\n",
    "        for i, ym in enumerate(fcst_months):\n",
    "            outputs.append((bu, pno, ym, float(q10[i]), float(q50[i]), float(q90[i])))\n",
    "\n",
    "fcst_df = pl.DataFrame(outputs, schema=[\"gbm_cd\", \"part_no\", \"fcst_yyyymm\", \"q10\", \"q50\", \"q90\"])"
   ],
   "id": "a906988f3ba9f0d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/xgf_87rd5nz9rsbc143wp9qc0000gn/T/ipykernel_51768/1209026078.py:57: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  fcst_df = pl.DataFrame(outputs, schema=[\"gbm_cd\", \"part_no\", \"fcst_yyyymm\", \"q10\", \"q50\", \"q90\"])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:23:03.521865Z",
     "start_time": "2025-10-28T12:23:00.177281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fcst_df = (fcst_df\n",
    "            .with_columns(pl.col('part_no').map_elements(lambda x: x[0], pl.Utf8).alias('part_no')))\n",
    "fcst_df"
   ],
   "id": "ab3b367b6db2a1a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5_267_760, 6)\n",
       "┌────────┬───────────┬─────────────┬──────────┬──────────┬──────────┐\n",
       "│ gbm_cd ┆ part_no   ┆ fcst_yyyymm ┆ q10      ┆ q50      ┆ q90      │\n",
       "│ ---    ┆ ---       ┆ ---         ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str    ┆ str       ┆ i64         ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞════════╪═══════════╪═════════════╪══════════╪══════════╪══════════╡\n",
       "│ VD     ┆ 0001-1001 ┆ 202703      ┆ 0.036268 ┆ 0.045336 ┆ 0.054403 │\n",
       "│ VD     ┆ 0001-1001 ┆ 202704      ┆ 0.036281 ┆ 0.045351 ┆ 0.054421 │\n",
       "│ VD     ┆ 0001-1001 ┆ 202705      ┆ 0.036292 ┆ 0.045365 ┆ 0.054438 │\n",
       "│ VD     ┆ 0001-1001 ┆ 202706      ┆ 0.036302 ┆ 0.045378 ┆ 0.054453 │\n",
       "│ VD     ┆ 0001-1001 ┆ 202707      ┆ 0.036312 ┆ 0.04539  ┆ 0.054468 │\n",
       "│ …      ┆ …         ┆ …           ┆ …        ┆ …        ┆ …        │\n",
       "│ VD     ┆ ZZ90239   ┆ 203610      ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ VD     ┆ ZZ90239   ┆ 203611      ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ VD     ┆ ZZ90239   ┆ 203612      ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ VD     ┆ ZZ90239   ┆ 203701      ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ VD     ┆ ZZ90239   ┆ 203702      ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "└────────┴───────────┴─────────────┴──────────┴──────────┴──────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_267_760, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gbm_cd</th><th>part_no</th><th>fcst_yyyymm</th><th>q10</th><th>q50</th><th>q90</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;VD&quot;</td><td>&quot;0001-1001&quot;</td><td>202703</td><td>0.036268</td><td>0.045336</td><td>0.054403</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;0001-1001&quot;</td><td>202704</td><td>0.036281</td><td>0.045351</td><td>0.054421</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;0001-1001&quot;</td><td>202705</td><td>0.036292</td><td>0.045365</td><td>0.054438</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;0001-1001&quot;</td><td>202706</td><td>0.036302</td><td>0.045378</td><td>0.054453</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;0001-1001&quot;</td><td>202707</td><td>0.036312</td><td>0.04539</td><td>0.054468</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;ZZ90239&quot;</td><td>203610</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;ZZ90239&quot;</td><td>203611</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;ZZ90239&quot;</td><td>203612</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;ZZ90239&quot;</td><td>203701</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;ZZ90239&quot;</td><td>203702</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:23:15.550587Z",
     "start_time": "2025-10-28T12:23:15.541151Z"
    }
   },
   "cell_type": "code",
   "source": "fcst_df.filter(pl.col('part_no') == \"B\")",
   "id": "17989964462c8d15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (120, 6)\n",
       "┌────────┬─────────┬─────────────┬─────┬─────┬─────┐\n",
       "│ gbm_cd ┆ part_no ┆ fcst_yyyymm ┆ q10 ┆ q50 ┆ q90 │\n",
       "│ ---    ┆ ---     ┆ ---         ┆ --- ┆ --- ┆ --- │\n",
       "│ str    ┆ str     ┆ i64         ┆ f64 ┆ f64 ┆ f64 │\n",
       "╞════════╪═════════╪═════════════╪═════╪═════╪═════╡\n",
       "│ VD     ┆ B       ┆ 202703      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 202704      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 202705      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 202706      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 202707      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ …      ┆ …       ┆ …           ┆ …   ┆ …   ┆ …   │\n",
       "│ VD     ┆ B       ┆ 203610      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 203611      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 203612      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 203701      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "│ VD     ┆ B       ┆ 203702      ┆ 0.0 ┆ 0.0 ┆ 0.0 │\n",
       "└────────┴─────────┴─────────────┴─────┴─────┴─────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (120, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gbm_cd</th><th>part_no</th><th>fcst_yyyymm</th><th>q10</th><th>q50</th><th>q90</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>202703</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>202704</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>202705</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>202706</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>202707</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>203610</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>203611</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>203612</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>203701</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;VD&quot;</td><td>&quot;B&quot;</td><td>203702</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:23:03.667665Z",
     "start_time": "2025-10-28T12:23:03.666318Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "83080e2b705ae601",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

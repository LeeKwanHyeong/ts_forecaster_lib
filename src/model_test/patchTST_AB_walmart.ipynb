{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PatchTST AB Test (Walmart) — Refactored Notebook\n",
    "\n",
    "Variants:\n",
    "- **A0**: y-only (no exogenous)\n",
    "- **A1**: time/calendar exogenous (sin/cos)\n",
    "- **A2**: time/calendar + holiday (vectorized, batch-safe)\n",
    "\n",
    "Key fixes:\n",
    "- `compose_exo_calendar_cb` supports **batched** `start_idx` so the DataLoader collate can call it once per batch.\n",
    "- `get_train_loader(batch_size=...)` is called explicitly to avoid silent fallback to the default 32.\n"
   ],
   "id": "16ad9283735bdd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:04.213399Z",
     "start_time": "2026-01-14T01:42:02.530679Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# LTB modules (expected to exist in your repo)\n",
    "from modeling_module.data_loader import MultiPartExoDataModule\n",
    "from modeling_module.training.model_trainers.total_train import run_total_train_weekly\n",
    "\n",
    "# optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "https://developer.nvidia.com/cuda-12-8-0-download-archive\n",
    "'''\n",
    "\n",
    "MAC_DIR = \"/Users/igwanhyeong/PycharmProjects/ts_forecaster_lib/raw_data/\"\n",
    "WINDOW_DIR = \"C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/\"\n",
    "\n",
    "DIR = WINDOW_DIR if sys.platform == \"win32\" else MAC_DIR\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"DIR:\", DIR)\n",
    "print(\"device:\", device)\n",
    "if device == \"cuda\":\n",
    "    print(\"cuda:\", torch.version.cuda, \"gpu_count:\", torch.cuda.device_count())\n",
    "\n",
    "save_dir = os.path.join(DIR, \"fit\", \"walmart_patchtst_ab\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_root_A0 = os.path.join(save_dir, \"A0_y_only\")\n",
    "save_root_A1 = os.path.join(save_dir, \"A1_time_exog\")\n",
    "save_root_A2 = os.path.join(save_dir, \"A2_time_holiday\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR: C:/Users/USER/PycharmProjects/ts_forecaster_lib/raw_data/\n",
      "device: cuda\n",
      "cuda: 12.8 gpu_count: 1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:04.812436Z",
     "start_time": "2026-01-14T01:42:04.797323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "walmart_df = pl.read_parquet(DIR + 'train_data/walmart_train.parquet')\n",
    "walmart_df.head()"
   ],
   "id": "1312e3d40db1518e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬────────┬──────────┬────────────┐\n",
       "│ unique_id ┆ dt     ┆ y        ┆ is_holiday │\n",
       "│ ---       ┆ ---    ┆ ---      ┆ ---        │\n",
       "│ i64       ┆ i64    ┆ f64      ┆ bool       │\n",
       "╞═══════════╪════════╪══════════╪════════════╡\n",
       "│ 1         ┆ 201005 ┆ 24924.5  ┆ false      │\n",
       "│ 1         ┆ 201006 ┆ 46039.49 ┆ true       │\n",
       "│ 1         ┆ 201007 ┆ 41595.55 ┆ false      │\n",
       "│ 1         ┆ 201008 ┆ 19403.54 ┆ false      │\n",
       "│ 1         ┆ 201009 ┆ 21827.9  ┆ false      │\n",
       "└───────────┴────────┴──────────┴────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>unique_id</th><th>dt</th><th>y</th><th>is_holiday</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>1</td><td>201005</td><td>24924.5</td><td>false</td></tr><tr><td>1</td><td>201006</td><td>46039.49</td><td>true</td></tr><tr><td>1</td><td>201007</td><td>41595.55</td><td>false</td></tr><tr><td>1</td><td>201008</td><td>19403.54</td><td>false</td></tr><tr><td>1</td><td>201009</td><td>21827.9</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:05.399110Z",
     "start_time": "2026-01-14T01:42:05.395859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lookback = 52\n",
    "horizon = 27\n",
    "batch_size = 512\n",
    "\n",
    "freq = \"weekly\"          # walmart dt is weekly\n",
    "split_mode = \"multi\"     # id-disjoint split (leakage-safe)\n",
    "shuffle = True\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"device:\", device)"
   ],
   "id": "f25a758d076a79e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:06.188381Z",
     "start_time": "2026-01-14T01:42:06.023449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# YYYYWW -> day_idx (Monday of ISO week)\n",
    "# day_idx: days since 1970-01-01 (int)\n",
    "# -----------------------------\n",
    "EPOCH = date(1970, 1, 1)\n",
    "\n",
    "def _yyyyww_to_monday_dayidx(yyyyww: int) -> int:\n",
    "    y = int(yyyyww) // 100\n",
    "    w = int(yyyyww) % 100\n",
    "    monday = date.fromisocalendar(y, w, 1)\n",
    "    return (monday - EPOCH).days\n",
    "\n",
    "from datetime import date, timedelta\n",
    "\n",
    "\n",
    "def _monday_dayidx_to_yyyyww(dayidx: int) -> int:\n",
    "    \"\"\"\n",
    "    dayidx: days since 1970-01-01 (EPOCH)\n",
    "    가정: dayidx는 '월요일'에 해당하는 날짜(ISO week Monday)\n",
    "    반환: YYYYWW (int)\n",
    "    \"\"\"\n",
    "    d = EPOCH + timedelta(days=int(dayidx))\n",
    "    iso_y, iso_w, iso_d = d.isocalendar()\n",
    "\n",
    "    # 안전장치: monday로 만든 값이 아니면 여기서 바로 티나게 함(원하면 제거 가능)\n",
    "    # iso_d: Monday=1 ... Sunday=7\n",
    "    if iso_d != 1:\n",
    "        # 월요일이 아니어도 해당 날짜가 속한 ISO week로 변환은 가능하지만,\n",
    "        # 지금 파이프라인 의도(week anchor)가 깨졌을 수 있어 경고 성격으로 둠\n",
    "        # raise ValueError(f\"dayidx={dayidx} is not Monday (iso_d={iso_d})\")\n",
    "        pass\n",
    "\n",
    "    return int(iso_y) * 100 + int(iso_w)\n",
    "\n",
    "df = (\n",
    "    walmart_df\n",
    "    .with_columns([\n",
    "        pl.col(\"unique_id\").cast(pl.Utf8),\n",
    "        pl.col(\"dt\").cast(pl.Int32).alias(\"yyyyww\"),\n",
    "        pl.col(\"y\").cast(pl.Float32),\n",
    "        pl.col(\"is_holiday\").cast(pl.Float32).alias(\"exo_is_holiday\"),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col(\"yyyyww\").map_elements(_yyyyww_to_monday_dayidx, return_dtype=pl.Int32).alias(\"date_idx\")\n",
    "    ])\n",
    "    .with_columns([pl.col(\"yyyyww\").alias(\"date\")])\n",
    "    .select([\"unique_id\", \"date\", \"date_idx\", \"y\", \"exo_is_holiday\"])\n",
    ")\n",
    "\n",
    "# # Optional: complete missing weeks per store (step=7 days), fill y=0, holiday=0\n",
    "# def complete_weekly(g: pl.DataFrame) -> pl.DataFrame:\n",
    "#     g = g.sort(\"date_idx\")\n",
    "#     mn = int(g[\"date_idx\"].min())\n",
    "#     mx = int(g[\"date_idx\"].max())\n",
    "#     full = pl.DataFrame({\"date_idx\": pl.int_range(mn, mx + 1, step=7, eager=True).cast(pl.Int32)})\n",
    "#     out = full.join(g, on=\"date_idx\", how=\"left\").with_columns([\n",
    "#         pl.col(\"unique_id\").fill_null(g[\"unique_id\"][0]),\n",
    "#         pl.col(\"date\").fill_null(pl.col(\"date_idx\").map_elements(_monday_dayidx_to_yyyyww, return_dtype=pl.Int32)),\n",
    "#         pl.col(\"y\").fill_null(0.0),\n",
    "#         pl.col(\"exo_is_holiday\").fill_null(0.0),\n",
    "#     ])\n",
    "#     return out\n",
    "#\n",
    "# df = pl.concat([complete_weekly(g) for g in df.partition_by(\"unique_id\")], how=\"vertical\").sort([\"unique_id\",\"date_idx\"])\n",
    "#\n",
    "# print(\"df:\", df.shape)\n",
    "# df\n",
    "df"
   ],
   "id": "2814024c5dccb337",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (421_570, 5)\n",
       "┌───────────┬────────┬──────────┬──────────────┬────────────────┐\n",
       "│ unique_id ┆ date   ┆ date_idx ┆ y            ┆ exo_is_holiday │\n",
       "│ ---       ┆ ---    ┆ ---      ┆ ---          ┆ ---            │\n",
       "│ str       ┆ i32    ┆ i32      ┆ f32          ┆ f32            │\n",
       "╞═══════════╪════════╪══════════╪══════════════╪════════════════╡\n",
       "│ 1         ┆ 201005 ┆ 14641    ┆ 24924.5      ┆ 0.0            │\n",
       "│ 1         ┆ 201006 ┆ 14648    ┆ 46039.488281 ┆ 1.0            │\n",
       "│ 1         ┆ 201007 ┆ 14655    ┆ 41595.550781 ┆ 0.0            │\n",
       "│ 1         ┆ 201008 ┆ 14662    ┆ 19403.539062 ┆ 0.0            │\n",
       "│ 1         ┆ 201009 ┆ 14669    ┆ 21827.900391 ┆ 0.0            │\n",
       "│ …         ┆ …      ┆ …        ┆ …            ┆ …              │\n",
       "│ 45        ┆ 201239 ┆ 15607    ┆ 508.369995   ┆ 0.0            │\n",
       "│ 45        ┆ 201240 ┆ 15614    ┆ 628.099976   ┆ 0.0            │\n",
       "│ 45        ┆ 201241 ┆ 15621    ┆ 1061.02002   ┆ 0.0            │\n",
       "│ 45        ┆ 201242 ┆ 15628    ┆ 760.01001    ┆ 0.0            │\n",
       "│ 45        ┆ 201243 ┆ 15635    ┆ 1076.800049  ┆ 0.0            │\n",
       "└───────────┴────────┴──────────┴──────────────┴────────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (421_570, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>unique_id</th><th>date</th><th>date_idx</th><th>y</th><th>exo_is_holiday</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;1&quot;</td><td>201005</td><td>14641</td><td>24924.5</td><td>0.0</td></tr><tr><td>&quot;1&quot;</td><td>201006</td><td>14648</td><td>46039.488281</td><td>1.0</td></tr><tr><td>&quot;1&quot;</td><td>201007</td><td>14655</td><td>41595.550781</td><td>0.0</td></tr><tr><td>&quot;1&quot;</td><td>201008</td><td>14662</td><td>19403.539062</td><td>0.0</td></tr><tr><td>&quot;1&quot;</td><td>201009</td><td>14669</td><td>21827.900391</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;45&quot;</td><td>201239</td><td>15607</td><td>508.369995</td><td>0.0</td></tr><tr><td>&quot;45&quot;</td><td>201240</td><td>15614</td><td>628.099976</td><td>0.0</td></tr><tr><td>&quot;45&quot;</td><td>201241</td><td>15621</td><td>1061.02002</td><td>0.0</td></tr><tr><td>&quot;45&quot;</td><td>201242</td><td>15628</td><td>760.01001</td><td>0.0</td></tr><tr><td>&quot;45&quot;</td><td>201243</td><td>15635</td><td>1076.800049</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:07.167814Z",
     "start_time": "2026-01-14T01:42:07.164322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling_module.utils.exogenous_utils import compose_exo_calendar_cb\n",
    "\n",
    "future_exo_cb_time = compose_exo_calendar_cb(date_type=freq)\n",
    "future_exo_cb_time"
   ],
   "id": "a664615f7d1fb139",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function modeling_module.utils.exogenous_utils.compose_exo_calendar_cb.<locals>.cb(start_idx: Union[int, Sequence[int], numpy.ndarray], H: int, device: str = 'cpu')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:08.174933Z",
     "start_time": "2026-01-14T01:42:08.165753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Holiday lookup (vectorized) + FutureExo callback (time + holiday)\n",
    "# ============================================================\n",
    "holiday_map_dayidx = {\n",
    "    int(row[0]): float(row[1])\n",
    "    for row in (\n",
    "        df.select([\"date_idx\", \"exo_is_holiday\"])\n",
    "          .group_by(\"date_idx\")\n",
    "          .agg(pl.max(\"exo_is_holiday\").alias(\"exo_is_holiday\"))\n",
    "          .sort(\"date_idx\")\n",
    "          .iter_rows()\n",
    "    )\n",
    "}\n",
    "\n",
    "def build_holiday_array(holiday_map_dayidx: dict[int, float], *, pad: int = 0) -> np.ndarray:\n",
    "    if not holiday_map_dayidx:\n",
    "        return np.zeros((1,), dtype=np.float32)\n",
    "    max_k = max(int(k) for k in holiday_map_dayidx.keys())\n",
    "    arr = np.zeros((max_k + 1 + int(pad),), dtype=np.float32)\n",
    "    for k, v in holiday_map_dayidx.items():\n",
    "        kk = int(k)\n",
    "        if kk >= 0:\n",
    "            arr[kk] = float(v)\n",
    "    return arr\n",
    "\n",
    "class FutureExoTimePlusHoliday:\n",
    "    def __init__(self, holiday_by_dayidx: np.ndarray, *, step_days: int = 7):\n",
    "        self.holiday = holiday_by_dayidx.astype(np.float32, copy=False)\n",
    "        self.step_days = int(step_days)\n",
    "\n",
    "    def __call__(self, start_idx, H: int, device: str = \"cpu\"):\n",
    "        # 1) calendar exo (batch-safe)\n",
    "        cal = future_exo_cb_time(start_idx, H, device=device)  # scalar: (H,E) | batch: (B,H,E)\n",
    "\n",
    "        # 2) holiday exo (vectorized in numpy)\n",
    "        is_scalar = isinstance(start_idx, (int, np.integer))\n",
    "        if is_scalar:\n",
    "            s = np.asarray([int(start_idx)], dtype=np.int64)\n",
    "        else:\n",
    "            s = np.asarray(start_idx, dtype=np.int64).reshape(-1)\n",
    "\n",
    "        B = s.shape[0]\n",
    "        H = int(H)\n",
    "\n",
    "        offsets = (self.step_days * np.arange(H, dtype=np.int64))[None, :]  # (1,H)\n",
    "        idx = s[:, None] + offsets                                          # (B,H)\n",
    "\n",
    "        hol = np.zeros((B, H), dtype=np.float32)\n",
    "        valid = (idx >= 0) & (idx < self.holiday.shape[0])\n",
    "        hol[valid] = self.holiday[idx[valid]]\n",
    "        hol_t = torch.from_numpy(hol).unsqueeze(-1)                         # (B,H,1), CPU\n",
    "\n",
    "        target_device = cal.device  # cal이 이미 cuda일 수 있음\n",
    "        cal = cal.to(target_device, dtype=torch.float32)\n",
    "        hol_t = hol_t.to(target_device, dtype=torch.float32)\n",
    "\n",
    "        # 3) concat\n",
    "        if is_scalar:\n",
    "            out = torch.cat([cal.to(torch.float32).unsqueeze(0), hol_t], dim=-1)[0]  # (H,E+1)\n",
    "        else:\n",
    "            out = torch.cat([cal.to(torch.float32), hol_t], dim=-1)                  # (B,H,E+1)\n",
    "\n",
    "        return out\n",
    "\n",
    "holiday_by_dayidx = build_holiday_array(holiday_map_dayidx, pad=7 * (horizon + 2))\n",
    "future_exo_cb_time_plus_holiday = FutureExoTimePlusHoliday(holiday_by_dayidx, step_days=7)\n"
   ],
   "id": "271418db8989f81b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:09.186851Z",
     "start_time": "2026-01-14T01:42:08.772513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Build DataModules / Loaders (A0/A1/A2)\n",
    "# ============================================================\n",
    "def build_datamodule(variant: str) -> MultiPartExoDataModule:\n",
    "    if variant == \"A0\":\n",
    "        future_exo_cb = None\n",
    "    elif variant == \"A1\":\n",
    "        future_exo_cb = future_exo_cb_time\n",
    "    elif variant == \"A2\":\n",
    "        future_exo_cb = future_exo_cb_time_plus_holiday\n",
    "    else:\n",
    "        raise ValueError(variant)\n",
    "\n",
    "    return MultiPartExoDataModule(\n",
    "        df=df,\n",
    "        id_col=\"unique_id\",\n",
    "        date_col=\"date\",\n",
    "        y_col=\"y\",\n",
    "        lookback=lookback,\n",
    "        horizon=horizon,\n",
    "        batch_size=batch_size,\n",
    "        past_exo_cont_cols=None,\n",
    "        past_exo_cat_cols=None,\n",
    "        future_exo_cb=future_exo_cb,\n",
    "        freq=freq,\n",
    "        shuffle=shuffle,\n",
    "        split_mode=split_mode,\n",
    "    )\n",
    "\n",
    "data_module_A0 = build_datamodule(\"A0\")\n",
    "data_module_A1 = build_datamodule(\"A1\")\n",
    "data_module_A2 = build_datamodule(\"A2\")\n",
    "\n",
    "# IMPORTANT: pass batch_size explicitly to avoid default(32) inside get_train_loader()\n",
    "train_loader_A0 = data_module_A0.get_train_loader(batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_A0   = data_module_A0.get_val_loader()\n",
    "\n",
    "train_loader_A1 = data_module_A1.get_train_loader(batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_A1   = data_module_A1.get_val_loader()\n",
    "\n",
    "train_loader_A2 = data_module_A2.get_train_loader(batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_A2   = data_module_A2.get_val_loader()\n",
    "\n",
    "def inspect(loader, name: str):\n",
    "    t0 = time.time()\n",
    "    x, y, uid, fe, pe_cont, pe_cat = next(iter(loader))\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(f\"[{name}] batch_time: {dt:.3f}s\")\n",
    "    print(f\"[{name}] x : {tuple(x.shape)} | {x.device} | {x.dtype}\")\n",
    "    print(f\"[{name}] fe: {tuple(fe.shape)} | {fe.device} | {fe.dtype}\")\n",
    "    print(f\"[{name}] future_exo_cb is None?: {loader.collate_fn.future_exo_cb is None}\")\n",
    "    if fe.shape[-1] > 0:\n",
    "        print(f\"[{name}] fe sample (first 3 steps):\\n{fe[0, :3, :]}\")\n",
    "\n",
    "inspect(train_loader_A0, \"A0\")\n",
    "inspect(train_loader_A1, \"A1\")\n",
    "inspect(train_loader_A2, \"A2\")\n"
   ],
   "id": "a5b455b948f09a0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A0] batch_time: 0.105s\n",
      "[A0] x : (512, 52, 1) | cpu | torch.float32\n",
      "[A0] fe: (512, 27, 0) | cpu | torch.float32\n",
      "[A0] future_exo_cb is None?: True\n",
      "[future_exo_cb] batch call OK | miss=512 | time=0.001s\n",
      "[A1] batch_time: 0.016s\n",
      "[A1] x : (512, 52, 1) | cpu | torch.float32\n",
      "[A1] fe: (512, 27, 2) | cpu | torch.float32\n",
      "[A1] future_exo_cb is None?: False\n",
      "[A1] fe sample (first 3 steps):\n",
      "tensor([[-1.2028e-01,  9.9274e-01],\n",
      "        [ 5.2432e-04,  1.0000e+00],\n",
      "        [ 1.2132e-01,  9.9261e-01]])\n",
      "[future_exo_cb] batch call OK | miss=512 | time=0.000s\n",
      "[A2] batch_time: 0.017s\n",
      "[A2] x : (512, 52, 1) | cpu | torch.float32\n",
      "[A2] fe: (512, 27, 3) | cpu | torch.float32\n",
      "[A2] future_exo_cb is None?: False\n",
      "[A2] fe sample (first 3 steps):\n",
      "tensor([[ 0.8849, -0.4657,  0.0000],\n",
      "        [ 0.8233, -0.5676,  0.0000],\n",
      "        [ 0.7487, -0.6629,  0.0000]])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:42:10.126831Z",
     "start_time": "2026-01-14T01:42:10.088834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inspect(loader, name):\n",
    "    b = next(iter(loader))\n",
    "    x, y, uid, fe, pe_cont, pe_cat = b\n",
    "    print(f\"[{name}] x:\", x.shape, x.device, x.dtype)\n",
    "    print(f\"[{name}] fe:\", fe.shape, fe.device, fe.dtype)\n",
    "    print(f\"[{name}] future_exo_cb is None?\", loader.collate_fn.future_exo_cb is None)\n",
    "    if fe.shape[-1] > 0:\n",
    "        print(f\"[{name}] fe sample:\", fe[0, :3, :])\n",
    "\n",
    "# inspect(train_loader_A0, \"A0\")\n",
    "inspect(train_loader_A1, \"A1\")\n",
    "# inspect(train_loader_A2, \"A2\")\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "b = next(iter(train_loader_A1))\n",
    "print(\"first batch ok, dt=\", time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "b = next(iter(val_loader_A1))\n",
    "print(\"first val batch ok, dt=\", time.time() - t0)"
   ],
   "id": "de74a51e555ffeaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A1] x: torch.Size([512, 52, 1]) cpu torch.float32\n",
      "[A1] fe: torch.Size([512, 27, 2]) cpu torch.float32\n",
      "[A1] future_exo_cb is None? False\n",
      "[A1] fe sample: tensor([[ 0.6617, -0.7498],\n",
      "        [ 0.5679, -0.8231],\n",
      "        [ 0.4643, -0.8857]])\n",
      "first batch ok, dt= 0.01300191879272461\n",
      "[future_exo_cb] batch call OK | miss=512 | time=0.001s\n",
      "first val batch ok, dt= 0.00599980354309082\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:49:09.072965Z",
     "start_time": "2026-01-14T01:47:03.835805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# CELL 5) 학습 실행 (LTB total_train 포맷 유지)\n",
    "# - 여기서는 \"외생변수 A/B/C\"만 비교하므로 use_ssl_pretrain=False로 고정\n",
    "# ============================================\n",
    "from modeling_module.training.model_trainers.total_train import run_total_train_weekly\n",
    "print('run result_A0')\n",
    "# results_A0 = run_total_train_weekly(\n",
    "#     train_loader_A0,\n",
    "#     val_loader_A0,\n",
    "#     device=device,\n",
    "#     lookback=lookback,\n",
    "#     horizon=horizon,\n",
    "#     warmup_epochs=5,\n",
    "#     spike_epochs=10,\n",
    "#     save_dir=save_root_A0,\n",
    "#     use_exogenous_mode = False,\n",
    "#     models_to_run=[\"patchtst\"],\n",
    "#     use_ssl_pretrain=False,\n",
    "# )\n",
    "\n",
    "# print('run result_A1')\n",
    "# results_A1 = run_total_train_weekly(\n",
    "#     train_loader_A1,\n",
    "#     val_loader_A1,\n",
    "#     device=device,\n",
    "#     lookback=lookback,\n",
    "#     horizon=horizon,\n",
    "#     warmup_epochs=5,\n",
    "#     spike_epochs=10,\n",
    "#     save_dir=save_root_A1,\n",
    "#     use_exogenous_mode = True,\n",
    "#     models_to_run=[\"patchtst\"],\n",
    "#     use_ssl_pretrain=False,\n",
    "# )\n",
    "\n",
    "print('run result_A2')\n",
    "results_A2 = run_total_train_weekly(\n",
    "    train_loader_A2,\n",
    "    val_loader_A2,\n",
    "    device=device,\n",
    "    lookback=lookback,\n",
    "    horizon=horizon,\n",
    "    warmup_epochs=5,\n",
    "    spike_epochs=10,\n",
    "    save_dir=save_root_A2,\n",
    "    use_exogenous_mode = True,\n",
    "    models_to_run=[\"patchtst\"],\n",
    "    use_ssl_pretrain=False,\n",
    ")\n"
   ],
   "id": "c20028e485691c02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run result_A0\n",
      "run result_A2\n",
      "\n",
      "[total_train] === RUN: patchtst (weekly) ===\n",
      "exogenous dimension:: 2\n",
      "PatchTST Base (Weekly)\n",
      "[future_exo_cb] batch call OK | miss=9 | time=0.001s\n",
      "[train_patchtst] point head rebuilt: d_future 2 -> 3\n",
      "[train_patchtst] loader provides fe_cont(E=3), so future_exo_cb disabled.\n",
      "\n",
      "[train_patchtst] ===== Stage 1/2 =====\n",
      "  - spike: OFF\n",
      "  - epochs: 5 | lr=0.0003 | horizon_decay=False\n",
      "[train_patchtst] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 5,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 5,\n",
      "  \"lr\": 0.0003,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": false,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": false,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[future_exo_cb] batch call OK | miss=512 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=470 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=498 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=477 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=495 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=466 | time=0.001s\n",
      "[future_exo_cb] batch call OK | miss=463 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=503 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=501 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=480 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=479 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=470 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=492 | time=0.000s\n",
      "[future_exo_cb] batch call OK | miss=419 | time=0.000s\n",
      "Epoch 1/5 | LR 0.000300 | Train 8677.293228 | Val 6975.376031\n",
      "Epoch 2/5 | LR 0.000298 | Train 7675.495854 | Val 6563.204123\n",
      "Epoch 3/5 | LR 0.000296 | Train 7108.349107 | Val 6282.539890\n",
      "Epoch 4/5 | LR 0.000293 | Train 6680.401575 | Val 6054.610356\n",
      "Epoch 5/5 | LR 0.000289 | Train 6353.325357 | Val 5898.895252\n",
      "\n",
      "[train_patchtst] ===== Stage 2/2 =====\n",
      "  - spike: ON\n",
      "  - epochs: 10 | lr=9.999999999999999e-05 | horizon_decay=True\n",
      "[train_patchtst] Effective TrainingConfig:\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 10,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "[CommonTrainer] TrainingConfig (final)\n",
      "{\n",
      "  \"device\": \"cuda\",\n",
      "  \"log_every\": 100,\n",
      "  \"use_amp\": true,\n",
      "  \"lookback\": 52,\n",
      "  \"horizon\": 27,\n",
      "  \"epochs\": 10,\n",
      "  \"lr\": 9.999999999999999e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"t_max\": 40,\n",
      "  \"patience\": 100,\n",
      "  \"max_grad_norm\": 30.0,\n",
      "  \"amp_device\": \"cuda\",\n",
      "  \"loss_mode\": \"point\",\n",
      "  \"point_loss\": \"huber\",\n",
      "  \"huber_delta\": 0.8,\n",
      "  \"q_star\": 0.5,\n",
      "  \"use_cost_q_star\": false,\n",
      "  \"Cu\": 1.0,\n",
      "  \"Co\": 1.0,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.5,\n",
      "    0.9\n",
      "  ],\n",
      "  \"use_intermittent\": true,\n",
      "  \"alpha_zero\": 3.0,\n",
      "  \"alpha_pos\": 1.0,\n",
      "  \"gamma_run\": 0.3,\n",
      "  \"cap\": null,\n",
      "  \"use_horizon_decay\": true,\n",
      "  \"tau_h\": 0.85,\n",
      "  \"val_use_weights\": false,\n",
      "  \"spike_loss\": {\n",
      "    \"enabled\": true,\n",
      "    \"strategy\": \"mix\",\n",
      "    \"huber_delta\": 0.6,\n",
      "    \"asym_up_weight\": 1.0,\n",
      "    \"asym_down_weight\": 2.0,\n",
      "    \"mad_k\": 1.5,\n",
      "    \"w_spike\": 4.0,\n",
      "    \"w_norm\": 1.0,\n",
      "    \"alpha_huber\": 0.6,\n",
      "    \"beta_asym\": 0.4,\n",
      "    \"mix_with_baseline\": false,\n",
      "    \"gamma_baseline\": 0.0\n",
      "  },\n",
      "  \"lambda_hist_scale\": 0.1,\n",
      "  \"lambda_hist_var\": 0.03,\n",
      "  \"hist_window\": 12,\n",
      "  \"anchor_last_k\": 8,\n",
      "  \"anchor_weight\": 0.05\n",
      "}\n",
      "Epoch 1/10 | LR 0.000100 | Train 129110153.798450 | Val 127617619.674419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 37\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# results_A0 = run_total_train_weekly(\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m#     train_loader_A0,\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m#     val_loader_A0,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     33\u001B[39m \u001B[38;5;66;03m#     use_ssl_pretrain=False,\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[32m     36\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mrun result_A2\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m results_A2 = \u001B[43mrun_total_train_weekly\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader_A2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_loader_A2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlookback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlookback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhorizon\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhorizon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m    \u001B[49m\u001B[43mspike_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_root_A2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_exogenous_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodels_to_run\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpatchtst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_ssl_pretrain\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\model_trainers\\total_train.py:638\u001B[39m, in \u001B[36mrun_total_train_weekly\u001B[39m\u001B[34m(train_loader, val_loader, device, lookback, horizon, warmup_epochs, spike_epochs, base_lr, save_dir, use_exogenous_mode, models_to_run, use_ssl_pretrain, ssl_pretrain_epochs, ssl_mask_ratio, ssl_loss_type, ssl_freeze_encoder_before_ft)\u001B[39m\n\u001B[32m    619\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_total_train_weekly\u001B[39m(\n\u001B[32m    620\u001B[39m         train_loader,\n\u001B[32m    621\u001B[39m         val_loader,\n\u001B[32m   (...)\u001B[39m\u001B[32m    636\u001B[39m         ssl_freeze_encoder_before_ft: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    637\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m638\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_run_total_train_generic\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    639\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    640\u001B[39m \u001B[43m        \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    641\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    642\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlookback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    643\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhorizon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    644\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mweekly\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m        \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    646\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_exogenous_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_exogenous_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    647\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwarmup_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarmup_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    648\u001B[39m \u001B[43m        \u001B[49m\u001B[43mspike_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mspike_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbase_lr\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbase_lr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodels_to_run\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodels_to_run\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    651\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_ssl_pretrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_ssl_pretrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    652\u001B[39m \u001B[43m        \u001B[49m\u001B[43mssl_pretrain_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mssl_pretrain_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    653\u001B[39m \u001B[43m        \u001B[49m\u001B[43mssl_mask_ratio\u001B[49m\u001B[43m=\u001B[49m\u001B[43mssl_mask_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    654\u001B[39m \u001B[43m        \u001B[49m\u001B[43mssl_loss_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mssl_loss_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    655\u001B[39m \u001B[43m        \u001B[49m\u001B[43mssl_freeze_encoder_before_ft\u001B[49m\u001B[43m=\u001B[49m\u001B[43mssl_freeze_encoder_before_ft\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    656\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\model_trainers\\total_train.py:612\u001B[39m, in \u001B[36m_run_total_train_generic\u001B[39m\u001B[34m(train_loader, val_loader, device, lookback, horizon, freq, save_dir, use_exogenous_mode, models_to_run, warmup_epochs, spike_epochs, base_lr, use_ssl_pretrain, ssl_pretrain_epochs, ssl_mask_ratio, ssl_loss_type, ssl_freeze_encoder_before_ft)\u001B[39m\n\u001B[32m    603\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m m == \u001B[33m\"\u001B[39m\u001B[33mpatchtst\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    604\u001B[39m         kwargs.update(\u001B[38;5;28mdict\u001B[39m(\n\u001B[32m    605\u001B[39m             use_ssl_pretrain=use_ssl_pretrain,\n\u001B[32m    606\u001B[39m             ssl_pretrain_epochs=ssl_pretrain_epochs,\n\u001B[32m   (...)\u001B[39m\u001B[32m    609\u001B[39m             ssl_freeze_encoder_before_ft=ssl_freeze_encoder_before_ft,\n\u001B[32m    610\u001B[39m         ))\n\u001B[32m--> \u001B[39m\u001B[32m612\u001B[39m     \u001B[43mMODEL_REGISTRY\u001B[49m\u001B[43m[\u001B[49m\u001B[43mm\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    614\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\model_trainers\\total_train.py:293\u001B[39m, in \u001B[36m_run_patchtst\u001B[39m\u001B[34m(results, freq, train_loader, val_loader, save_root, lookback, horizon, future_exo_cb, exo_dim, patch_len, stride, point_train_cfg, quantile_train_cfg, stages, device, use_exogenous_mode, use_ssl_pretrain, ssl_pretrain_epochs, ssl_mask_ratio, ssl_loss_type, ssl_freeze_encoder_before_ft)\u001B[39m\n\u001B[32m    283\u001B[39m     best_pt_base = train_patchtst_finetune(\n\u001B[32m    284\u001B[39m         pt_base, train_loader, val_loader,\n\u001B[32m    285\u001B[39m         train_cfg=point_train_cfg, stages=\u001B[38;5;28mlist\u001B[39m(stages),\n\u001B[32m   (...)\u001B[39m\u001B[32m    290\u001B[39m         freeze_encoder_before_ft=ssl_freeze_encoder_before_ft,\n\u001B[32m    291\u001B[39m     )\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m293\u001B[39m     best_pt_base = \u001B[43mtrain_patchtst\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpt_base\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_cfg\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpoint_train_cfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstages\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfuture_exo_cb\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfuture_exo_cb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_exogenous_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_exogenous_mode\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m save_root:\n\u001B[32m    301\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33msave_root:: \u001B[39m\u001B[33m'\u001B[39m, save_root)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\model_trainers\\patchtst_train.py:198\u001B[39m, in \u001B[36mtrain_patchtst\u001B[39m\u001B[34m(model, train_loader, val_loader, stages, train_cfg, future_exo_cb, exo_is_normalized, use_exogenous_mode)\u001B[39m\n\u001B[32m    187\u001B[39m     tl_i = _maybe_make_spike_loader(train_loader, enable=cfg_i.spike_loss.enabled)\n\u001B[32m    189\u001B[39m     trainer = CommonTrainer(\n\u001B[32m    190\u001B[39m         cfg=cfg_i,\n\u001B[32m    191\u001B[39m         adapter=adapter,\n\u001B[32m   (...)\u001B[39m\u001B[32m    196\u001B[39m         use_exogenous_mode = use_exogenous_mode\n\u001B[32m    197\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m198\u001B[39m     model = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtl_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtta_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    199\u001B[39m     best = {\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model, \u001B[33m\"\u001B[39m\u001B[33mcfg\u001B[39m\u001B[33m\"\u001B[39m: cfg_i}\n\u001B[32m    201\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[EXO-train] inferred E=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | future_exo_cb? \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuture_exo_cb\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | exo_is_normalized=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexo_is_normalized\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\engine.py:302\u001B[39m, in \u001B[36mCommonTrainer.fit\u001B[39m\u001B[34m(self, model, train_loader, val_loader, tta_steps)\u001B[39m\n\u001B[32m    299\u001B[39m     \u001B[38;5;28mself\u001B[39m.adapter.tta_reset(model)\n\u001B[32m    301\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.cfg.epochs):\n\u001B[32m--> \u001B[39m\u001B[32m302\u001B[39m     train_loss = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    304\u001B[39m     \u001B[38;5;66;03m# ---- Validation ----\u001B[39;00m\n\u001B[32m    305\u001B[39m     model.eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\engine.py:229\u001B[39m, in \u001B[36mCommonTrainer._run_epoch\u001B[39m\u001B[34m(self, model, loader, train)\u001B[39m\n\u001B[32m    227\u001B[39m \u001B[38;5;66;03m# future_exo 결정 (배치 > cb)\u001B[39;00m\n\u001B[32m    228\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_exogenous_mode:\n\u001B[32m--> \u001B[39m\u001B[32m229\u001B[39m     future_exo = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_resolve_future_exo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfe_cont\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    231\u001B[39m     future_exo = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\engine.py:130\u001B[39m, in \u001B[36mCommonTrainer._resolve_future_exo\u001B[39m\u001B[34m(self, batch_future_exo, x, y, device)\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m exo \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    129\u001B[39m     exo = torch.nan_to_num(exo, nan=\u001B[32m0.0\u001B[39m, posinf=\u001B[32m1e6\u001B[39m, neginf=-\u001B[32m1e6\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m130\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_nan_stat\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfuture_exo\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    131\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m exo\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ts_forecaster_lib\\src\\modeling_module\\training\\engine.py:141\u001B[39m, in \u001B[36mCommonTrainer._nan_stat\u001B[39m\u001B[34m(self, name, t)\u001B[39m\n\u001B[32m    139\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m finite_mask.any():\n\u001B[32m    140\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m141\u001B[39m         mx = \u001B[43mt\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfinite_mask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mabs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    142\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    143\u001B[39m         mx = t[finite_mask].to(torch.float32).abs().max().item()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from modeling_module.utils.metrics import mae, smape\n",
    "\n",
    "from modeling_module.utils.metrics import rmse\n",
    "\n",
    "\n",
    "def load_model_ckpt(model, ckpt_path: str, device: str):\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state[\"model_state\"], strict=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_on_loader(model, loader, device: str, future_exo_cb=None):\n",
    "    model.eval()\n",
    "    ys, yhats = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[0].to(device)              # [B, 52, 1]\n",
    "        y = batch[1].to(device)              # [B, 27]\n",
    "        start_idx = batch[2]  # <-- 여기! 실제 batch 포맷에 맞게 수정 (현재 batch[2]가 part_ids일 수도 있음)\n",
    "\n",
    "        if future_exo_cb is not None:\n",
    "            # start_idx가 tensor면 python int로\n",
    "            if torch.is_tensor(start_idx):\n",
    "                start_idx = int(start_idx[0].item()) if start_idx.numel() > 0 else int(start_idx.item())\n",
    "            fe = future_exo_cb(start_idx, model.horizon, device=device)  # [H, D] 또는 [B,H,D] 규약 확인 필요\n",
    "            if fe.dim() == 2:\n",
    "                fe = fe.unsqueeze(0).expand(x.size(0), -1, -1)  # [B,H,D]\n",
    "            future_exo = fe.to(device)\n",
    "        else:\n",
    "            future_exo = None\n",
    "        past_exo_cont = batch[4].to(device)  # [B, 52, 11]\n",
    "        past_exo_cat = batch[5].to(device)   # [B, 52, 0]\n",
    "\n",
    "        # PatchTSTPointModel.forward 시그니처에 맞춰 전달\n",
    "        yhat = model(\n",
    "            x,\n",
    "            future_exo=future_exo,\n",
    "            past_exo_cont=past_exo_cont,\n",
    "            past_exo_cat=past_exo_cat,\n",
    "        )  # [B, 27]\n",
    "\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        yhats.append(yhat.detach().cpu().numpy())\n",
    "\n",
    "    y_all = np.concatenate(ys, axis=0)\n",
    "    yhat_all = np.concatenate(yhats, axis=0)\n",
    "    return y_all, yhat_all\n",
    "\n",
    "\n",
    "def _extract_pred_from_output(out, prefer_q=0.5):\n",
    "    \"\"\"\n",
    "    Quantile 모델 출력(out)이 dict/tuple/tensor 등일 수 있으므로\n",
    "    예측 텐서를 안전하게 꺼낸다.\n",
    "\n",
    "    반환:\n",
    "      - yhat_point: [B,H] (예: q=0.5 또는 첫 번째 출력)\n",
    "      - extra: 원본 out (필요 시 분석용)\n",
    "    \"\"\"\n",
    "    # 1) Tensor면 그대로\n",
    "    if torch.is_tensor(out):\n",
    "        return out, out\n",
    "\n",
    "    # 2) tuple/list면 첫 원소를 예측으로 가정\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        # 가장 흔한 케이스: (pred, aux) 또는 (q_pred, ...)\n",
    "        first = out[0]\n",
    "        if torch.is_tensor(first):\n",
    "            return first, out\n",
    "        # 더 복잡하면 아래 dict 로직으로 넘기기 위해 out를 dict처럼 처리 불가 -> 에러\n",
    "        raise TypeError(f\"Unsupported tuple/list output types: {[type(x) for x in out]}\")\n",
    "\n",
    "    # 3) dict면 키 후보들에서 찾기\n",
    "    if isinstance(out, dict):\n",
    "        # 흔한 키 후보들\n",
    "        key_candidates = [\n",
    "            \"yhat\", \"pred\", \"prediction\", \"y_pred\", \"output\",\n",
    "            \"q_pred\", \"quantiles\", \"yq\", \"y_hat\"\n",
    "        ]\n",
    "        for k in key_candidates:\n",
    "            if k in out and torch.is_tensor(out[k]):\n",
    "                t = out[k]\n",
    "                # [B,H] 또는 [B,H,Q] 또는 [B,Q,H] 등 가능\n",
    "                return _select_point_from_quantile_tensor(t, prefer_q=prefer_q), out\n",
    "\n",
    "        # dict 안에 텐서가 하나뿐이면 그걸 쓰기\n",
    "        tensor_items = [(k, v) for k, v in out.items() if torch.is_tensor(v)]\n",
    "        if len(tensor_items) == 1:\n",
    "            t = tensor_items[0][1]\n",
    "            return _select_point_from_quantile_tensor(t, prefer_q=prefer_q), out\n",
    "\n",
    "        raise KeyError(f\"Cannot find tensor prediction in dict output. keys={list(out.keys())}\")\n",
    "\n",
    "    raise TypeError(f\"Unsupported model output type: {type(out)}\")\n",
    "\n",
    "\n",
    "def _select_point_from_quantile_tensor(t: torch.Tensor, prefer_q=0.5):\n",
    "    \"\"\"\n",
    "    t가\n",
    "      - [B,H]이면 그대로\n",
    "      - [B,H,Q]이면 Q축에서 median(0.5)에 해당하는 index 선택\n",
    "      - [B,Q,H]이면 Q축에서 선택 후 [B,H]로\n",
    "    \"\"\"\n",
    "    if t.ndim == 2:\n",
    "        return t\n",
    "\n",
    "    if t.ndim == 3:\n",
    "        B, d1, d2 = t.shape\n",
    "\n",
    "        # [B,H,Q] 케이스 가정: d1이 horizon, d2가 quantile\n",
    "        # [B,Q,H] 케이스 가정: d1이 quantile, d2가 horizon\n",
    "        # heuristic: horizon은 보통 27 같은 값, quantile은 보통 3/5/9 등 작은 값\n",
    "        if d1 > d2:\n",
    "            # [B,H,Q]\n",
    "            q_dim = 2\n",
    "            q_len = d2\n",
    "            h_dim = 1\n",
    "        else:\n",
    "            # [B,Q,H]\n",
    "            q_dim = 1\n",
    "            q_len = d1\n",
    "            h_dim = 2\n",
    "\n",
    "        # prefer_q=0.5에 해당하는 index를 선택 (가능하면 중앙)\n",
    "        # q 값 리스트를 out에 포함하지 않는 경우가 많으니 중앙 index를 사용\n",
    "        q_idx = int(round((q_len - 1) * prefer_q))  # median index\n",
    "\n",
    "        if q_dim == 2:\n",
    "            # [B,H,Q] -> [B,H]\n",
    "            return t[:, :, q_idx]\n",
    "        else:\n",
    "            # [B,Q,H] -> [B,H]\n",
    "            return t[:, q_idx, :]\n",
    "\n",
    "    raise ValueError(f\"Unexpected prediction tensor shape: {t.shape}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_on_loader_quantile(model, loader, device, prefer_q=0.5, future_exo_cb=None):\n",
    "    model.eval()\n",
    "    ys, yhats = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        # 기존 unpack 유지 (당신 eval에서 batch[0], batch[1] ... 쓰는 구조)\n",
    "        x = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        # ---- 중요: future_exo 생성\n",
    "        # dataset이 start_idx를 batch에 포함하지 않으면, 아래 두 줄은 dataset에서 가져오는 방식으로 조정 필요\n",
    "        # 보통은 batch에 start_idx 또는 date_idx 같은 메타가 들어있거나, part_ids가 들어있습니다.\n",
    "        start_idx = batch[2]  # <-- 여기! 실제 batch 포맷에 맞게 수정 (현재 batch[2]가 part_ids일 수도 있음)\n",
    "        if future_exo_cb is not None:\n",
    "            # start_idx가 tensor면 python int로\n",
    "            if torch.is_tensor(start_idx):\n",
    "                start_idx = int(start_idx[0].item()) if start_idx.numel() > 0 else int(start_idx.item())\n",
    "            fe = future_exo_cb(start_idx, model.horizon, device=device)  # [H, D] 또는 [B,H,D] 규약 확인 필요\n",
    "            if fe.dim() == 2:\n",
    "                fe = fe.unsqueeze(0).expand(x.size(0), -1, -1)  # [B,H,D]\n",
    "            future_exo = fe.to(device)\n",
    "        else:\n",
    "            future_exo = None\n",
    "\n",
    "        past_exo_cont = batch[4].to(device)\n",
    "        past_exo_cat  = batch[5].to(device)\n",
    "\n",
    "        out = model(x, future_exo=future_exo, past_exo_cont=past_exo_cont, past_exo_cat=past_exo_cat)\n",
    "\n",
    "        yhat_point, _ = _extract_pred_from_output(out, prefer_q=prefer_q)\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        yhats.append(yhat_point.detach().cpu().numpy())\n",
    "\n",
    "    return np.concatenate(ys), np.concatenate(yhats)"
   ],
   "id": "fa17d29487977adf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# CELL 6) 체크포인트 로드 + 평가 (첨부 노트북 흐름 유지)\n",
    "# - quantile 모델이면 eval_on_loader_quantile 사용\n",
    "# - point 모델이면 eval_on_loader 사용\n",
    "# ============================================\n",
    "from modeling_module.utils.checkpoint import load_model_dict\n",
    "from modeling_module.models import build_patchTST_base, build_patchTST_quantile\n",
    "from modeling_module.utils.metrics import mae, smape, rmse\n",
    "\n",
    "# builders는 \"당신이 실제 저장한 모델 키\"에 맞추세요.\n",
    "# (첨부 노트북에서는 patchtst_quantile을 사용)\n",
    "builders = {\n",
    "    # \"patchtst_quantile\": build_patchTST_quantile,\n",
    "    \"patchtst\": build_patchTST_base,\n",
    "}\n",
    "\n",
    "# model_A0 = load_model_dict(save_root_A0, builders, device=device)[\"patchtst_quantile\"]\n",
    "# model_A1 = load_model_dict(save_root_A1, builders, device=device)[\"patchtst_quantile\"]\n",
    "# model_A2 = load_model_dict(save_root_A2, builders, device=device)[\"patchtst_quantile\"]\n",
    "model_A0 = load_model_dict(save_root_A0, builders, device = device)['patchtst']\n",
    "model_A1 = load_model_dict(save_root_A1, builders, device = device)['patchtst']\n",
    "model_A2 = load_model_dict(save_root_A2, builders, device = device)['patchtst']\n",
    "\n",
    "\n",
    "# 첨부 노트북에서 사용하던 eval 유틸을 그대로 쓴다고 가정합니다.\n",
    "# (이미 앞 셀에 정의돼 있거나, 별도 모듈에 있으면 import 하세요.)\n",
    "# from your_notebook_utils import eval_on_loader_quantile\n",
    "\n",
    "# y0, yhat0 = eval_on_loader_quantile(model_A0, val_loader_A0, device, prefer_q=0.5)\n",
    "# y1, yhat1 = eval_on_loader_quantile(model_A1, val_loader_A1, device, prefer_q=0.5, future_exo_cb = future_exo_cb_time)\n",
    "# y2, yhat2 = eval_on_loader_quantile(model_A2, val_loader_A2, device, prefer_q=0.5, future_exo_cb = future_exo_cb_time_plus_holiday)\n",
    "\n",
    "y0, yhat0 = eval_on_loader(model_A0, val_loader_A0, device=device)\n",
    "y1, yhat1 = eval_on_loader(model_A1, val_loader_A1, device=device, future_exo_cb = future_exo_cb_time)\n",
    "y2, yhat2 = eval_on_loader(model_A2, val_loader_A2, device=device, future_exo_cb = future_exo_cb_time_plus_holiday)\n",
    "\n",
    "metric_A0 = {\n",
    "    \"MAE\": float(mae(y0.reshape(-1), yhat0.reshape(-1))),\n",
    "    \"RMSE\": float(rmse(y0.reshape(-1), yhat0.reshape(-1))),\n",
    "    \"SMAPE\": float(smape(y0.reshape(-1), yhat0.reshape(-1))),\n",
    "}\n",
    "metric_A1 = {\n",
    "    \"MAE\": float(mae(y1.reshape(-1), yhat1.reshape(-1))),\n",
    "    \"RMSE\": float(rmse(y1.reshape(-1), yhat1.reshape(-1))),\n",
    "    \"SMAPE\": float(smape(y1.reshape(-1), yhat1.reshape(-1))),\n",
    "}\n",
    "metric_A2 = {\n",
    "    \"MAE\": float(mae(y2.reshape(-1), yhat2.reshape(-1))),\n",
    "    \"RMSE\": float(rmse(y2.reshape(-1), yhat2.reshape(-1))),\n",
    "    \"SMAPE\": float(smape(y2.reshape(-1), yhat2.reshape(-1))),\n",
    "}\n",
    "\n",
    "metric_A0, metric_A1, metric_A2"
   ],
   "id": "abf9b4cee0ec93f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, glob, torch\n",
    "\n",
    "def peek_ckpt(save_root):\n",
    "    ckpt_path = sorted(glob.glob(os.path.join(save_root, \"*.pt\")) +\n",
    "                       glob.glob(os.path.join(save_root, \"*.pth\")) +\n",
    "                       glob.glob(os.path.join(save_root, \"*.ckpt\")))[-1]\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    print(\"ckpt:\", ckpt_path)\n",
    "    cfg = ckpt.get(\"cfg\") or ckpt.get(\"config\") or ckpt.get(\"model_cfg\")\n",
    "    print(\"cfg type:\", type(cfg))\n",
    "    if isinstance(cfg, dict):\n",
    "        # 흔히 head 또는 d_future가 여기 들어있습니다.\n",
    "        print(\"cfg keys:\", list(cfg.keys())[:30])\n",
    "        if \"d_future\" in cfg: print(\"cfg[d_future] =\", cfg[\"d_future\"])\n",
    "        if \"head\" in cfg: print(\"cfg[head] =\", cfg[\"head\"])\n",
    "    else:\n",
    "        # dataclass/namespace일 수도\n",
    "        print(\"cfg dict:\", getattr(cfg, \"__dict__\", None))\n",
    "\n",
    "# peek_ckpt(save_root_A0)\n",
    "peek_ckpt(save_root_A1)\n",
    "# peek_ckpt(save_root_A2)\n"
   ],
   "id": "67d101b61b9d0d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# CELL 7) (선택) 예측 시각화 (첨부 노트북 스타일)\n",
    "# ============================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(y_true, preds: dict, max_n: int = 64):\n",
    "    n = min(max_n, y_true.shape[0])\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(12, 2.2*n), sharex=True)\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(n):\n",
    "        ax = axes[i]\n",
    "        ax.plot(y_true[i], label=\"true\")\n",
    "        for k, v in preds.items():\n",
    "            ax.plot(v[i], label=k)\n",
    "        ax.set_title(f\"sample={i}\", fontsize=9)\n",
    "        if i == 0:\n",
    "            ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(\n",
    "    y_true=y0,\n",
    "    preds={\n",
    "        \"A0_y_only\": yhat0,\n",
    "        \"A1_time\": yhat1,\n",
    "        \"A2_time+holiday\": yhat2,\n",
    "    },\n",
    "    max_n=32,\n",
    ")"
   ],
   "id": "b55203145b3ab0ee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
